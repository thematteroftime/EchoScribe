2025-08-24 01:02:15,798 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 01:02:16,712 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 01:02:16,712 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 01:02:16,712 - INFO - MainThread - 启动语音转写系统...
2025-08-24 01:02:16,715 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:16,716 - INFO - MainThread - SystemManager started
2025-08-24 01:02:16,716 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 01:02:16,716 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:16,717 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 01:02:16,718 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 01:02:16,719 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 01:02:16,719 - INFO - MainThread - 润色处理器已启动
2025-08-24 01:02:21,375 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 01:02:22,932 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:02:22,937 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:02:23,956 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 01:02:23,956 - INFO - WorkerThread-0 - excludes: None
2025-08-24 01:02:24,316 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 01:02:24,932 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:24,933 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 01:02:25,913 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 01:02:27,205 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:02:27,210 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:02:27,865 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 01:02:27,866 - INFO - WorkerThread-1 - excludes: None
2025-08-24 01:02:28,343 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 01:02:29,322 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:29,323 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 01:02:32,882 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 01:02:32,969 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 01:02:32,970 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 01:02:32,970 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 01:02:32,972 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:32,973 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:32,973 - INFO - WorkerThread-1 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 01:02:33,006 - INFO - WorkerThread-0 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 01:02:33,989 - INFO - WorkerThread-0 - 转写完成: 003.wav, 文本长度: 78
2025-08-24 01:02:33,990 - INFO - WorkerThread-0 - transcribed seq=3 len=78
2025-08-24 01:02:33,990 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:33,991 - INFO - WorkerThread-0 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 01:02:34,079 - INFO - WorkerThread-1 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 01:02:34,080 - INFO - WorkerThread-1 - transcribed seq=2 len=66
2025-08-24 01:02:34,080 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:34,080 - INFO - WorkerThread-1 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 01:02:34,969 - INFO - WorkerThread-1 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 01:02:34,969 - INFO - WorkerThread-1 - transcribed seq=5 len=130
2025-08-24 01:02:35,051 - INFO - WorkerThread-0 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 01:02:35,051 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:35,051 - WARNING - WorkerThread-0 - empty transcript, moved to failed handled in job
2025-08-24 01:02:35,052 - INFO - WorkerThread-1 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 01:02:35,052 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:35,055 - INFO - WorkerThread-0 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 01:02:35,780 - INFO - MergeThread - 合并完成: archive\full_000_to_005.txt
2025-08-24 01:02:35,982 - INFO - WorkerThread-1 - 转写完成: 006.wav, 文本长度: 246
2025-08-24 01:02:35,982 - INFO - WorkerThread-1 - transcribed seq=6 len=246
2025-08-24 01:02:35,984 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:35,984 - INFO - WorkerThread-1 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 01:02:36,083 - INFO - WorkerThread-0 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 01:02:36,084 - INFO - WorkerThread-0 - transcribed seq=7 len=234
2025-08-24 01:02:36,084 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:36,085 - INFO - WorkerThread-0 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 01:02:36,727 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 01:02:36,728 - INFO - PolishProcessor - 开始处理文件: full_000_to_005.txt
2025-08-24 01:02:37,049 - INFO - WorkerThread-1 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 01:02:37,051 - INFO - WorkerThread-1 - transcribed seq=8 len=195
2025-08-24 01:02:37,051 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:37,052 - INFO - WorkerThread-1 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 01:02:37,248 - INFO - WorkerThread-0 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 01:02:37,249 - INFO - WorkerThread-0 - transcribed seq=9 len=222
2025-08-24 01:02:37,249 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:37,250 - INFO - WorkerThread-0 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 01:02:38,086 - INFO - WorkerThread-1 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 01:02:38,088 - INFO - WorkerThread-1 - transcribed seq=10 len=230
2025-08-24 01:02:38,088 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:38,088 - INFO - WorkerThread-1 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 01:02:38,198 - INFO - WorkerThread-0 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 01:02:38,198 - INFO - WorkerThread-0 - transcribed seq=11 len=225
2025-08-24 01:02:38,199 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:38,199 - INFO - WorkerThread-0 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 01:02:39,053 - INFO - WorkerThread-1 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 01:02:39,053 - INFO - WorkerThread-1 - transcribed seq=12 len=111
2025-08-24 01:02:39,055 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:39,055 - INFO - WorkerThread-1 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 01:02:39,155 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 01:02:39,155 - INFO - WorkerThread-0 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 01:02:39,156 - INFO - WorkerThread-0 - transcribed seq=13 len=212
2025-08-24 01:02:39,156 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:39,156 - INFO - WorkerThread-0 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 01:02:40,034 - INFO - WorkerThread-1 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 01:02:40,034 - INFO - WorkerThread-1 - transcribed seq=14 len=190
2025-08-24 01:02:40,035 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:40,036 - INFO - WorkerThread-1 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 01:02:40,134 - INFO - WorkerThread-0 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 01:02:40,136 - INFO - WorkerThread-0 - transcribed seq=15 len=162
2025-08-24 01:02:40,136 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:40,136 - INFO - WorkerThread-0 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 01:02:40,990 - INFO - WorkerThread-1 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 01:02:40,991 - INFO - WorkerThread-1 - transcribed seq=16 len=134
2025-08-24 01:02:40,992 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:40,992 - INFO - WorkerThread-1 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 01:02:41,079 - INFO - WorkerThread-0 - 转写完成: 017.wav, 文本长度: 169
2025-08-24 01:02:41,079 - INFO - WorkerThread-0 - transcribed seq=17 len=169
2025-08-24 01:02:41,079 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:41,080 - INFO - WorkerThread-0 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 01:02:41,952 - INFO - WorkerThread-1 - 转写完成: 018.wav, 文本长度: 248
2025-08-24 01:02:41,952 - INFO - WorkerThread-1 - transcribed seq=18 len=248
2025-08-24 01:02:41,953 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:41,953 - INFO - WorkerThread-1 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 01:02:42,075 - INFO - WorkerThread-0 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 01:02:42,075 - INFO - WorkerThread-0 - transcribed seq=19 len=215
2025-08-24 01:02:42,076 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:42,076 - INFO - WorkerThread-0 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 01:02:42,949 - INFO - WorkerThread-1 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 01:02:42,950 - INFO - WorkerThread-1 - transcribed seq=20 len=214
2025-08-24 01:02:42,950 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:42,950 - INFO - WorkerThread-1 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 01:02:43,046 - INFO - WorkerThread-0 - 转写完成: 021.wav, 文本长度: 218
2025-08-24 01:02:43,046 - INFO - WorkerThread-0 - transcribed seq=21 len=218
2025-08-24 01:02:43,047 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:43,047 - INFO - WorkerThread-0 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 01:02:43,913 - INFO - WorkerThread-1 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 01:02:43,915 - INFO - WorkerThread-1 - transcribed seq=22 len=183
2025-08-24 01:02:43,916 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:43,917 - INFO - WorkerThread-1 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 01:02:44,026 - INFO - WorkerThread-0 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 01:02:44,026 - INFO - WorkerThread-0 - transcribed seq=23 len=223
2025-08-24 01:02:44,027 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:44,029 - INFO - WorkerThread-0 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 01:02:44,880 - INFO - WorkerThread-1 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 01:02:44,881 - INFO - WorkerThread-1 - transcribed seq=24 len=229
2025-08-24 01:02:44,881 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:44,882 - INFO - WorkerThread-1 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 01:02:44,974 - INFO - WorkerThread-0 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 01:02:44,974 - INFO - WorkerThread-0 - transcribed seq=25 len=198
2025-08-24 01:02:44,974 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:44,975 - INFO - WorkerThread-0 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 01:02:45,865 - INFO - WorkerThread-0 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 01:02:45,866 - INFO - WorkerThread-0 - transcribed seq=27 len=195
2025-08-24 01:02:45,867 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:45,868 - INFO - WorkerThread-0 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 01:02:46,003 - INFO - WorkerThread-1 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 01:02:46,003 - INFO - WorkerThread-1 - transcribed seq=26 len=184
2025-08-24 01:02:46,003 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:46,003 - INFO - WorkerThread-1 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 01:02:46,896 - INFO - WorkerThread-0 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 01:02:46,896 - INFO - WorkerThread-0 - transcribed seq=28 len=222
2025-08-24 01:02:46,897 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:46,897 - INFO - WorkerThread-0 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 01:02:47,022 - INFO - WorkerThread-1 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 01:02:47,023 - INFO - WorkerThread-1 - transcribed seq=29 len=164
2025-08-24 01:02:47,023 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:47,024 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 01:02:47,934 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 01:02:47,936 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 01:02:47,936 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:47,937 - INFO - WorkerThread-1 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 01:02:48,044 - INFO - WorkerThread-0 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 01:02:48,045 - INFO - WorkerThread-0 - transcribed seq=30 len=180
2025-08-24 01:02:48,046 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:48,046 - INFO - WorkerThread-0 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 01:02:48,984 - INFO - WorkerThread-1 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 01:02:48,984 - INFO - WorkerThread-1 - transcribed seq=32 len=211
2025-08-24 01:02:48,985 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:48,985 - INFO - WorkerThread-1 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 01:02:49,097 - INFO - WorkerThread-0 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 01:02:49,097 - INFO - WorkerThread-0 - transcribed seq=33 len=222
2025-08-24 01:02:49,098 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:49,098 - INFO - WorkerThread-0 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 01:02:50,047 - INFO - WorkerThread-1 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 01:02:50,047 - INFO - WorkerThread-1 - transcribed seq=34 len=130
2025-08-24 01:02:50,047 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:50,048 - INFO - WorkerThread-1 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 01:02:50,139 - INFO - WorkerThread-0 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 01:02:50,139 - INFO - WorkerThread-0 - transcribed seq=35 len=203
2025-08-24 01:02:50,139 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:50,141 - INFO - WorkerThread-0 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 01:02:51,062 - INFO - WorkerThread-1 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 01:02:51,063 - INFO - WorkerThread-1 - transcribed seq=36 len=127
2025-08-24 01:02:51,063 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:51,063 - INFO - WorkerThread-1 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 01:02:51,184 - INFO - WorkerThread-0 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 01:02:51,185 - INFO - WorkerThread-0 - transcribed seq=37 len=78
2025-08-24 01:02:51,185 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:51,185 - INFO - WorkerThread-0 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 01:02:52,127 - INFO - WorkerThread-0 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 01:02:52,128 - INFO - WorkerThread-0 - transcribed seq=39 len=199
2025-08-24 01:02:52,128 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:52,129 - INFO - WorkerThread-0 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 01:02:52,227 - INFO - WorkerThread-1 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 01:02:52,227 - INFO - WorkerThread-1 - transcribed seq=38 len=149
2025-08-24 01:02:52,228 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:52,228 - INFO - WorkerThread-1 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 01:02:53,201 - INFO - WorkerThread-1 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 01:02:53,201 - INFO - WorkerThread-1 - transcribed seq=41 len=232
2025-08-24 01:02:53,202 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:53,203 - INFO - WorkerThread-1 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 01:02:53,307 - INFO - WorkerThread-0 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 01:02:53,307 - INFO - WorkerThread-0 - transcribed seq=40 len=194
2025-08-24 01:02:53,308 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:53,308 - INFO - WorkerThread-0 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 01:02:54,264 - INFO - WorkerThread-0 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 01:02:54,265 - INFO - WorkerThread-0 - transcribed seq=43 len=202
2025-08-24 01:02:54,370 - INFO - WorkerThread-1 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 01:02:54,370 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:54,371 - INFO - WorkerThread-1 - transcribed seq=42 len=203
2025-08-24 01:02:54,372 - INFO - WorkerThread-0 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 01:02:54,372 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:54,376 - INFO - WorkerThread-1 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 01:02:55,366 - INFO - WorkerThread-1 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 01:02:55,478 - INFO - WorkerThread-1 - transcribed seq=45 len=207
2025-08-24 01:02:55,478 - INFO - WorkerThread-0 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 01:02:55,480 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:55,480 - INFO - WorkerThread-0 - transcribed seq=44 len=199
2025-08-24 01:02:55,481 - INFO - WorkerThread-1 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 01:02:55,481 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:55,486 - INFO - WorkerThread-0 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 01:02:55,791 - INFO - MergeThread - 合并完成: archive\full_006_to_045.txt
2025-08-24 01:02:56,396 - INFO - WorkerThread-1 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 01:02:56,396 - INFO - WorkerThread-1 - transcribed seq=46 len=212
2025-08-24 01:02:56,397 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:56,397 - INFO - WorkerThread-1 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 01:02:56,541 - INFO - WorkerThread-0 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 01:02:56,543 - INFO - WorkerThread-0 - transcribed seq=47 len=173
2025-08-24 01:02:56,544 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:56,544 - INFO - WorkerThread-0 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 01:02:57,442 - INFO - WorkerThread-1 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 01:02:57,443 - INFO - WorkerThread-1 - transcribed seq=48 len=236
2025-08-24 01:02:57,443 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:57,445 - INFO - WorkerThread-1 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 01:02:57,553 - INFO - WorkerThread-0 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 01:02:57,553 - INFO - WorkerThread-0 - transcribed seq=49 len=185
2025-08-24 01:02:57,554 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:57,555 - INFO - WorkerThread-0 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 01:02:58,501 - INFO - WorkerThread-1 - 转写完成: 050.wav, 文本长度: 186
2025-08-24 01:02:58,502 - INFO - WorkerThread-1 - transcribed seq=50 len=186
2025-08-24 01:02:58,502 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:58,503 - INFO - WorkerThread-1 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 01:02:58,636 - INFO - WorkerThread-0 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 01:02:58,638 - INFO - WorkerThread-0 - transcribed seq=51 len=163
2025-08-24 01:02:58,639 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:58,639 - INFO - WorkerThread-0 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 01:02:59,644 - INFO - WorkerThread-1 - 转写完成: 052.wav, 文本长度: 166
2025-08-24 01:02:59,645 - INFO - WorkerThread-1 - transcribed seq=52 len=166
2025-08-24 01:02:59,646 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:02:59,647 - INFO - WorkerThread-1 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 01:02:59,763 - INFO - WorkerThread-0 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 01:02:59,764 - INFO - WorkerThread-0 - transcribed seq=53 len=176
2025-08-24 01:03:00,239 - INFO - WorkerThread-1 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 01:03:00,240 - INFO - WorkerThread-1 - transcribed seq=54 len=121
2025-08-24 01:03:02,855 - INFO - PolishProcessor - 润色成功，文本长度: 442 -> 524
2025-08-24 01:03:02,856 - INFO - PolishProcessor - 润色完成: full_000_to_005.txt -> polished_full_000_to_005.txt (耗时: 26.10秒)
2025-08-24 01:03:04,869 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 01:03:04,870 - INFO - PolishProcessor - 开始处理文件: full_006_to_045.txt
2025-08-24 01:03:06,260 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 01:03:15,801 - INFO - MergeThread - 合并完成: archive\full_046_to_054.txt
2025-08-24 01:03:36,293 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.394447 seconds
2025-08-24 01:03:38,770 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 01:04:08,785 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.810511 seconds
2025-08-24 01:04:11,555 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 01:04:41,564 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect9\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 01:04:41,608 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 01:04:41,609 - INFO - PolishProcessor - 润色无变化或失败: full_006_to_045.txt
2025-08-24 01:04:43,622 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 01:04:43,623 - INFO - PolishProcessor - 开始处理文件: full_046_to_054.txt
2025-08-24 01:04:45,117 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 01:05:15,136 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.447429 seconds
2025-08-24 01:05:17,030 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 01:05:47,041 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.935271 seconds
2025-08-24 01:05:49,533 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 01:06:19,540 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect9\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 01:06:19,569 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 01:06:19,571 - INFO - PolishProcessor - 润色无变化或失败: full_046_to_054.txt
2025-08-24 01:22:03,865 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 01:22:04,939 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 01:22:04,939 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 01:22:04,939 - INFO - MainThread - 启动语音转写系统...
2025-08-24 01:22:04,942 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:04,942 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:04,942 - INFO - MainThread - SystemManager started
2025-08-24 01:22:04,943 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 01:22:04,944 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 01:22:04,944 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 01:22:04,946 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 01:22:04,946 - INFO - MainThread - 润色处理器已启动
2025-08-24 01:22:09,633 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 01:22:11,205 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:22:11,209 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:22:12,268 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 01:22:12,269 - INFO - WorkerThread-1 - excludes: None
2025-08-24 01:22:12,617 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 01:22:13,259 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:13,260 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 01:22:14,587 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 01:22:15,978 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:22:15,984 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 01:22:17,356 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 01:22:17,357 - INFO - WorkerThread-0 - excludes: None
2025-08-24 01:22:17,934 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 01:22:20,809 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:20,809 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 01:22:21,157 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 01:22:21,157 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 01:22:21,157 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:21,183 - INFO - WorkerThread-1 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 01:22:22,152 - INFO - WorkerThread-1 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 01:22:22,152 - INFO - WorkerThread-1 - transcribed seq=2 len=66
2025-08-24 01:22:22,153 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:22,153 - INFO - WorkerThread-1 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 01:22:22,299 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 01:22:22,300 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 01:22:22,300 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:22,301 - INFO - WorkerThread-0 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 01:22:23,116 - INFO - WorkerThread-1 - 转写完成: 003.wav, 文本长度: 78
2025-08-24 01:22:23,117 - INFO - WorkerThread-1 - transcribed seq=3 len=78
2025-08-24 01:22:23,117 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:23,118 - INFO - WorkerThread-1 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 01:22:23,240 - INFO - WorkerThread-0 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 01:22:23,241 - WARNING - WorkerThread-0 - empty transcript, moved to failed handled in job
2025-08-24 01:22:23,242 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:23,243 - INFO - WorkerThread-0 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 01:22:23,856 - INFO - MergeThread - 合并完成: archive\full_000_to_003.txt
2025-08-24 01:22:24,058 - INFO - WorkerThread-1 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 01:22:24,059 - INFO - WorkerThread-1 - transcribed seq=5 len=130
2025-08-24 01:22:24,059 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:24,060 - INFO - WorkerThread-1 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 01:22:24,249 - INFO - WorkerThread-0 - 转写完成: 006.wav, 文本长度: 245
2025-08-24 01:22:24,250 - INFO - WorkerThread-0 - transcribed seq=6 len=245
2025-08-24 01:22:24,251 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:24,252 - INFO - WorkerThread-0 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 01:22:24,349 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 01:22:24,349 - INFO - PolishProcessor - 开始处理文件: full_000_to_003.txt
2025-08-24 01:22:24,742 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:22:24,744 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 01:22:24,744 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:22:24,745 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 01:22:24,745 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:22:24,745 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 01:22:24,746 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 01:22:24,746 - INFO - PolishProcessor - 润色无变化或失败: full_000_to_003.txt
2025-08-24 01:22:25,140 - INFO - WorkerThread-1 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 01:22:25,140 - INFO - WorkerThread-1 - transcribed seq=7 len=234
2025-08-24 01:22:25,141 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:25,142 - INFO - WorkerThread-1 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 01:22:25,309 - INFO - WorkerThread-0 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 01:22:25,310 - INFO - WorkerThread-0 - transcribed seq=8 len=195
2025-08-24 01:22:25,310 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:25,311 - INFO - WorkerThread-0 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 01:22:26,177 - INFO - WorkerThread-0 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 01:22:26,178 - INFO - WorkerThread-0 - transcribed seq=10 len=230
2025-08-24 01:22:26,178 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:26,178 - INFO - WorkerThread-0 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 01:22:26,294 - INFO - WorkerThread-1 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 01:22:26,295 - INFO - WorkerThread-1 - transcribed seq=9 len=222
2025-08-24 01:22:26,295 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:26,296 - INFO - WorkerThread-1 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 01:22:27,169 - INFO - WorkerThread-0 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 01:22:27,170 - INFO - WorkerThread-0 - transcribed seq=11 len=225
2025-08-24 01:22:27,171 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:27,171 - INFO - WorkerThread-0 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 01:22:27,322 - INFO - WorkerThread-1 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 01:22:27,323 - INFO - WorkerThread-1 - transcribed seq=12 len=111
2025-08-24 01:22:27,324 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:27,325 - INFO - WorkerThread-1 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 01:22:28,283 - INFO - WorkerThread-0 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 01:22:28,284 - INFO - WorkerThread-0 - transcribed seq=13 len=212
2025-08-24 01:22:28,285 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:28,285 - INFO - WorkerThread-0 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 01:22:28,419 - INFO - WorkerThread-1 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 01:22:28,420 - INFO - WorkerThread-1 - transcribed seq=14 len=190
2025-08-24 01:22:28,421 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:28,422 - INFO - WorkerThread-1 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 01:22:29,371 - INFO - WorkerThread-0 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 01:22:29,372 - INFO - WorkerThread-0 - transcribed seq=15 len=162
2025-08-24 01:22:29,373 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:29,373 - INFO - WorkerThread-0 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 01:22:29,490 - INFO - WorkerThread-1 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 01:22:29,490 - INFO - WorkerThread-1 - transcribed seq=16 len=134
2025-08-24 01:22:29,491 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:29,491 - INFO - WorkerThread-1 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 01:22:30,350 - INFO - WorkerThread-0 - 转写完成: 017.wav, 文本长度: 169
2025-08-24 01:22:30,350 - INFO - WorkerThread-0 - transcribed seq=17 len=169
2025-08-24 01:22:30,351 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:30,352 - INFO - WorkerThread-0 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 01:22:30,546 - INFO - WorkerThread-1 - 转写完成: 018.wav, 文本长度: 244
2025-08-24 01:22:30,547 - INFO - WorkerThread-1 - transcribed seq=18 len=244
2025-08-24 01:22:30,547 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:30,548 - INFO - WorkerThread-1 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 01:22:31,332 - INFO - WorkerThread-0 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 01:22:31,332 - INFO - WorkerThread-0 - transcribed seq=19 len=215
2025-08-24 01:22:31,333 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:31,333 - INFO - WorkerThread-0 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 01:22:31,543 - INFO - WorkerThread-1 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 01:22:31,544 - INFO - WorkerThread-1 - transcribed seq=20 len=214
2025-08-24 01:22:31,546 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:31,546 - INFO - WorkerThread-1 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 01:22:32,316 - INFO - WorkerThread-0 - 转写完成: 021.wav, 文本长度: 219
2025-08-24 01:22:32,317 - INFO - WorkerThread-0 - transcribed seq=21 len=219
2025-08-24 01:22:32,318 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:32,318 - INFO - WorkerThread-0 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 01:22:32,607 - INFO - WorkerThread-1 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 01:22:32,609 - INFO - WorkerThread-1 - transcribed seq=22 len=183
2025-08-24 01:22:32,609 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:32,610 - INFO - WorkerThread-1 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 01:22:33,252 - INFO - WorkerThread-0 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 01:22:33,252 - INFO - WorkerThread-0 - transcribed seq=23 len=223
2025-08-24 01:22:33,253 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:33,254 - INFO - WorkerThread-0 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 01:22:33,697 - INFO - WorkerThread-1 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 01:22:33,698 - INFO - WorkerThread-1 - transcribed seq=24 len=229
2025-08-24 01:22:33,698 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:33,699 - INFO - WorkerThread-1 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 01:22:34,093 - INFO - WorkerThread-0 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 01:22:34,094 - INFO - WorkerThread-0 - transcribed seq=25 len=198
2025-08-24 01:22:34,094 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:34,094 - INFO - WorkerThread-0 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 01:22:34,831 - INFO - WorkerThread-1 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 01:22:34,832 - INFO - WorkerThread-1 - transcribed seq=26 len=184
2025-08-24 01:22:34,833 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:34,834 - INFO - WorkerThread-1 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 01:22:34,966 - INFO - WorkerThread-0 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 01:22:34,966 - INFO - WorkerThread-0 - transcribed seq=27 len=195
2025-08-24 01:22:34,967 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:34,967 - INFO - WorkerThread-0 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 01:22:35,808 - INFO - WorkerThread-0 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 01:22:35,808 - INFO - WorkerThread-0 - transcribed seq=29 len=164
2025-08-24 01:22:35,809 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:35,809 - INFO - WorkerThread-0 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 01:22:35,970 - INFO - WorkerThread-1 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 01:22:35,971 - INFO - WorkerThread-1 - transcribed seq=28 len=222
2025-08-24 01:22:35,971 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:35,972 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 01:22:36,748 - INFO - WorkerThread-0 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 01:22:36,749 - INFO - WorkerThread-0 - transcribed seq=30 len=180
2025-08-24 01:22:36,750 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:36,751 - INFO - WorkerThread-0 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 01:22:36,878 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 01:22:36,879 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 01:22:36,880 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:36,882 - INFO - WorkerThread-1 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 01:22:37,716 - INFO - WorkerThread-0 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 01:22:37,717 - INFO - WorkerThread-0 - transcribed seq=32 len=211
2025-08-24 01:22:37,717 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:37,718 - INFO - WorkerThread-0 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 01:22:37,827 - INFO - WorkerThread-1 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 01:22:37,828 - INFO - WorkerThread-1 - transcribed seq=33 len=222
2025-08-24 01:22:37,828 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:37,829 - INFO - WorkerThread-1 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 01:22:38,662 - INFO - WorkerThread-0 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 01:22:38,662 - INFO - WorkerThread-0 - transcribed seq=34 len=130
2025-08-24 01:22:38,663 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:38,663 - INFO - WorkerThread-0 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 01:22:38,778 - INFO - WorkerThread-1 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 01:22:38,778 - INFO - WorkerThread-1 - transcribed seq=35 len=203
2025-08-24 01:22:38,779 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:38,779 - INFO - WorkerThread-1 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 01:22:39,606 - INFO - WorkerThread-0 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 01:22:39,607 - INFO - WorkerThread-0 - transcribed seq=36 len=127
2025-08-24 01:22:39,607 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:39,608 - INFO - WorkerThread-0 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 01:22:39,704 - INFO - WorkerThread-1 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 01:22:39,706 - INFO - WorkerThread-1 - transcribed seq=37 len=78
2025-08-24 01:22:39,706 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:39,706 - INFO - WorkerThread-1 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 01:22:40,557 - INFO - WorkerThread-0 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 01:22:40,558 - INFO - WorkerThread-0 - transcribed seq=38 len=149
2025-08-24 01:22:40,558 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:40,559 - INFO - WorkerThread-0 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 01:22:40,666 - INFO - WorkerThread-1 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 01:22:40,666 - INFO - WorkerThread-1 - transcribed seq=39 len=199
2025-08-24 01:22:40,667 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:40,668 - INFO - WorkerThread-1 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 01:22:41,523 - INFO - WorkerThread-0 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 01:22:41,524 - INFO - WorkerThread-0 - transcribed seq=40 len=194
2025-08-24 01:22:41,524 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:41,525 - INFO - WorkerThread-0 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 01:22:41,620 - INFO - WorkerThread-1 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 01:22:41,621 - INFO - WorkerThread-1 - transcribed seq=41 len=232
2025-08-24 01:22:41,621 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:41,621 - INFO - WorkerThread-1 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 01:22:42,491 - INFO - WorkerThread-1 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 01:22:42,492 - INFO - WorkerThread-1 - transcribed seq=43 len=202
2025-08-24 01:22:42,493 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:42,493 - INFO - WorkerThread-1 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 01:22:42,634 - INFO - WorkerThread-0 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 01:22:42,634 - INFO - WorkerThread-0 - transcribed seq=42 len=203
2025-08-24 01:22:42,635 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:42,635 - INFO - WorkerThread-0 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 01:22:43,456 - INFO - WorkerThread-1 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 01:22:43,457 - INFO - WorkerThread-1 - transcribed seq=44 len=199
2025-08-24 01:22:43,457 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:43,457 - INFO - WorkerThread-1 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 01:22:43,627 - INFO - WorkerThread-0 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 01:22:43,627 - INFO - WorkerThread-0 - transcribed seq=45 len=207
2025-08-24 01:22:43,628 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:43,628 - INFO - WorkerThread-0 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 01:22:43,860 - INFO - MergeThread - 合并完成: archive\full_005_to_045.txt
2025-08-24 01:22:43,969 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 01:22:43,969 - INFO - PolishProcessor - 开始处理文件: full_005_to_045.txt
2025-08-24 01:22:43,986 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:22:43,987 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 01:22:43,987 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:22:43,987 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 01:22:43,988 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:22:43,988 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 01:22:43,989 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 01:22:43,989 - INFO - PolishProcessor - 润色完成: full_005_to_045.txt -> polished_full_005_to_045.txt (耗时: 0.00秒)
2025-08-24 01:22:44,441 - INFO - WorkerThread-1 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 01:22:44,442 - INFO - WorkerThread-1 - transcribed seq=46 len=212
2025-08-24 01:22:44,443 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:44,443 - INFO - WorkerThread-1 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 01:22:44,594 - INFO - WorkerThread-0 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 01:22:44,595 - INFO - WorkerThread-0 - transcribed seq=47 len=173
2025-08-24 01:22:44,595 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:44,596 - INFO - WorkerThread-0 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 01:22:45,470 - INFO - WorkerThread-1 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 01:22:45,471 - INFO - WorkerThread-1 - transcribed seq=48 len=236
2025-08-24 01:22:45,471 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:45,472 - INFO - WorkerThread-1 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 01:22:45,613 - INFO - WorkerThread-0 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 01:22:45,614 - INFO - WorkerThread-0 - transcribed seq=49 len=185
2025-08-24 01:22:45,615 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:45,616 - INFO - WorkerThread-0 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 01:22:46,482 - INFO - WorkerThread-1 - 转写完成: 050.wav, 文本长度: 185
2025-08-24 01:22:46,482 - INFO - WorkerThread-1 - transcribed seq=50 len=185
2025-08-24 01:22:46,483 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:46,483 - INFO - WorkerThread-1 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 01:22:46,620 - INFO - WorkerThread-0 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 01:22:46,620 - INFO - WorkerThread-0 - transcribed seq=51 len=163
2025-08-24 01:22:46,621 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:46,622 - INFO - WorkerThread-0 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 01:22:47,478 - INFO - WorkerThread-1 - 转写完成: 052.wav, 文本长度: 166
2025-08-24 01:22:47,479 - INFO - WorkerThread-1 - transcribed seq=52 len=166
2025-08-24 01:22:47,480 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 01:22:47,481 - INFO - WorkerThread-1 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 01:22:47,607 - INFO - WorkerThread-0 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 01:22:47,608 - INFO - WorkerThread-0 - transcribed seq=53 len=176
2025-08-24 01:22:48,038 - INFO - WorkerThread-1 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 01:22:48,039 - INFO - WorkerThread-1 - transcribed seq=54 len=121
2025-08-24 01:23:03,865 - INFO - MergeThread - 合并完成: archive\full_046_to_054.txt
2025-08-24 01:23:04,211 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 01:23:04,211 - INFO - PolishProcessor - 开始处理文件: full_046_to_054.txt
2025-08-24 01:23:04,224 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:23:04,224 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 01:23:04,225 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:23:04,225 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 01:23:04,225 - ERROR - PolishProcessor - 润色处理异常: create() got an unexpected keyword argument 'request_timeout'
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 71, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
TypeError: create() got an unexpected keyword argument 'request_timeout'
2025-08-24 01:23:04,225 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 01:23:04,226 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 01:23:04,226 - INFO - PolishProcessor - 润色完成: full_046_to_054.txt -> polished_full_046_to_054.txt (耗时: 0.00秒)
2025-08-24 01:25:21,324 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 01:25:21,325 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 02:06:50,978 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 02:06:52,850 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 02:06:52,851 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 02:06:52,852 - INFO - MainThread - 启动语音转写系统...
2025-08-24 02:06:52,856 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:06:52,857 - INFO - MainThread - SystemManager started
2025-08-24 02:06:52,858 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 02:06:52,858 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:06:52,861 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 02:06:52,862 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 02:06:52,864 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 02:06:52,864 - INFO - MainThread - 润色处理器已启动
2025-08-24 02:06:57,526 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 02:07:00,839 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:07:00,848 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:07:02,097 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 02:07:02,098 - INFO - WorkerThread-0 - excludes: None
2025-08-24 02:07:02,655 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 02:07:03,312 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:07:05,347 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:05,349 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 02:07:07,250 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:07:07,263 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:07:09,119 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 02:07:09,120 - INFO - WorkerThread-1 - excludes: None
2025-08-24 02:07:10,307 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:07:13,872 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:13,874 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 02:07:21,369 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 02:07:21,369 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 02:07:21,370 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:21,552 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 02:07:21,553 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 02:07:21,555 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:21,556 - INFO - WorkerThread-1 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 02:07:21,568 - INFO - WorkerThread-0 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 02:07:23,295 - INFO - WorkerThread-1 - 转写完成: 003.wav, 文本长度: 79
2025-08-24 02:07:23,296 - INFO - WorkerThread-1 - transcribed seq=3 len=79
2025-08-24 02:07:23,297 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:23,298 - INFO - WorkerThread-1 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 02:07:23,461 - INFO - WorkerThread-0 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 02:07:23,462 - INFO - WorkerThread-0 - transcribed seq=2 len=66
2025-08-24 02:07:23,463 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:23,464 - INFO - WorkerThread-0 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 02:07:24,855 - INFO - WorkerThread-1 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 02:07:24,856 - WARNING - WorkerThread-1 - empty transcript, moved to failed handled in job
2025-08-24 02:07:24,857 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:24,858 - INFO - WorkerThread-1 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 02:07:25,201 - INFO - WorkerThread-0 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 02:07:25,201 - INFO - WorkerThread-0 - transcribed seq=5 len=130
2025-08-24 02:07:25,202 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:25,202 - INFO - WorkerThread-0 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 02:07:26,543 - INFO - WorkerThread-1 - 转写完成: 006.wav, 文本长度: 248
2025-08-24 02:07:26,547 - INFO - WorkerThread-1 - transcribed seq=6 len=248
2025-08-24 02:07:26,549 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:26,549 - INFO - WorkerThread-1 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 02:07:26,846 - INFO - WorkerThread-0 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 02:07:26,846 - INFO - WorkerThread-0 - transcribed seq=7 len=234
2025-08-24 02:07:26,850 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:26,851 - INFO - WorkerThread-0 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 02:07:28,524 - INFO - WorkerThread-1 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 02:07:28,524 - INFO - WorkerThread-0 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 02:07:28,525 - INFO - WorkerThread-1 - transcribed seq=8 len=195
2025-08-24 02:07:28,526 - INFO - WorkerThread-0 - transcribed seq=9 len=222
2025-08-24 02:07:28,527 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:28,528 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:28,528 - INFO - WorkerThread-1 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 02:07:28,528 - INFO - WorkerThread-0 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 02:07:30,174 - INFO - WorkerThread-1 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 02:07:30,176 - INFO - WorkerThread-1 - transcribed seq=10 len=230
2025-08-24 02:07:30,177 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:30,179 - INFO - WorkerThread-1 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 02:07:30,230 - INFO - MergeThread - 合并完成: archive\full_000_to_010.txt
2025-08-24 02:07:30,439 - INFO - WorkerThread-0 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 02:07:30,444 - INFO - WorkerThread-0 - transcribed seq=11 len=225
2025-08-24 02:07:30,448 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:30,449 - INFO - WorkerThread-0 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 02:07:30,576 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:07:30,578 - INFO - PolishProcessor - 开始处理文件: full_000_to_010.txt
2025-08-24 02:07:32,052 - INFO - WorkerThread-1 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 02:07:32,064 - INFO - WorkerThread-1 - transcribed seq=12 len=111
2025-08-24 02:07:32,065 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:32,067 - INFO - WorkerThread-1 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 02:07:32,273 - INFO - WorkerThread-0 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 02:07:32,277 - INFO - WorkerThread-0 - transcribed seq=13 len=212
2025-08-24 02:07:32,279 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:32,280 - INFO - WorkerThread-0 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 02:07:33,263 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:07:33,723 - INFO - WorkerThread-1 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 02:07:33,732 - INFO - WorkerThread-1 - transcribed seq=14 len=190
2025-08-24 02:07:33,733 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:33,734 - INFO - WorkerThread-1 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 02:07:34,019 - INFO - WorkerThread-0 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 02:07:34,019 - INFO - WorkerThread-0 - transcribed seq=15 len=162
2025-08-24 02:07:34,020 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:34,021 - INFO - WorkerThread-0 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 02:07:35,521 - INFO - WorkerThread-1 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 02:07:35,521 - INFO - WorkerThread-1 - transcribed seq=16 len=134
2025-08-24 02:07:35,522 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:35,523 - INFO - WorkerThread-1 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 02:07:35,735 - INFO - WorkerThread-0 - 转写完成: 017.wav, 文本长度: 170
2025-08-24 02:07:35,735 - INFO - WorkerThread-0 - transcribed seq=17 len=170
2025-08-24 02:07:35,736 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:35,737 - INFO - WorkerThread-0 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 02:07:37,321 - INFO - WorkerThread-1 - 转写完成: 018.wav, 文本长度: 248
2025-08-24 02:07:37,321 - INFO - WorkerThread-1 - transcribed seq=18 len=248
2025-08-24 02:07:37,322 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:37,323 - INFO - WorkerThread-1 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 02:07:37,512 - INFO - WorkerThread-0 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 02:07:37,513 - INFO - WorkerThread-0 - transcribed seq=19 len=215
2025-08-24 02:07:37,514 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:37,515 - INFO - WorkerThread-0 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 02:07:39,080 - INFO - WorkerThread-0 - 转写完成: 021.wav, 文本长度: 219
2025-08-24 02:07:39,080 - INFO - WorkerThread-1 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 02:07:39,080 - INFO - WorkerThread-0 - transcribed seq=21 len=219
2025-08-24 02:07:39,081 - INFO - WorkerThread-1 - transcribed seq=20 len=214
2025-08-24 02:07:39,082 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:39,083 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:39,084 - INFO - WorkerThread-0 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 02:07:39,084 - INFO - WorkerThread-1 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 02:07:40,416 - INFO - WorkerThread-1 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 02:07:40,417 - INFO - WorkerThread-1 - transcribed seq=23 len=223
2025-08-24 02:07:40,418 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:40,419 - INFO - WorkerThread-1 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 02:07:40,578 - INFO - WorkerThread-0 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 02:07:40,579 - INFO - WorkerThread-0 - transcribed seq=22 len=183
2025-08-24 02:07:40,580 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:40,581 - INFO - WorkerThread-0 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 02:07:41,871 - INFO - WorkerThread-1 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 02:07:41,872 - INFO - WorkerThread-1 - transcribed seq=24 len=229
2025-08-24 02:07:41,872 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:41,873 - INFO - WorkerThread-1 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 02:07:42,014 - INFO - WorkerThread-0 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 02:07:42,015 - INFO - WorkerThread-0 - transcribed seq=25 len=198
2025-08-24 02:07:42,016 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:42,017 - INFO - WorkerThread-0 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 02:07:43,061 - INFO - WorkerThread-1 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 02:07:43,061 - INFO - WorkerThread-1 - transcribed seq=26 len=184
2025-08-24 02:07:43,063 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:43,063 - INFO - WorkerThread-1 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 02:07:43,351 - INFO - WorkerThread-0 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 02:07:43,351 - INFO - WorkerThread-0 - transcribed seq=27 len=195
2025-08-24 02:07:43,351 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:43,352 - INFO - WorkerThread-0 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 02:07:44,086 - INFO - WorkerThread-1 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 02:07:44,087 - INFO - WorkerThread-1 - transcribed seq=28 len=222
2025-08-24 02:07:44,087 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:44,088 - INFO - WorkerThread-1 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 02:07:44,936 - INFO - WorkerThread-1 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 02:07:44,937 - INFO - WorkerThread-1 - transcribed seq=30 len=180
2025-08-24 02:07:44,937 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:44,938 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 02:07:45,042 - INFO - WorkerThread-0 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 02:07:45,047 - INFO - WorkerThread-0 - transcribed seq=29 len=164
2025-08-24 02:07:45,058 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:45,068 - INFO - WorkerThread-0 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 02:07:46,128 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 02:07:46,129 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 02:07:46,130 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:46,130 - INFO - WorkerThread-1 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 02:07:46,327 - INFO - WorkerThread-0 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 02:07:46,328 - INFO - WorkerThread-0 - transcribed seq=32 len=211
2025-08-24 02:07:46,328 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:46,329 - INFO - WorkerThread-0 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 02:07:47,381 - INFO - WorkerThread-1 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 02:07:47,384 - INFO - WorkerThread-1 - transcribed seq=33 len=222
2025-08-24 02:07:47,386 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:47,389 - INFO - WorkerThread-1 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 02:07:47,521 - INFO - WorkerThread-0 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 02:07:47,522 - INFO - WorkerThread-0 - transcribed seq=34 len=130
2025-08-24 02:07:47,523 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:47,524 - INFO - WorkerThread-0 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 02:07:48,264 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.394447 seconds
2025-08-24 02:07:48,638 - INFO - WorkerThread-0 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 02:07:48,639 - INFO - WorkerThread-0 - transcribed seq=36 len=127
2025-08-24 02:07:48,639 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:48,640 - INFO - WorkerThread-0 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 02:07:48,748 - INFO - WorkerThread-1 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 02:07:48,748 - INFO - WorkerThread-1 - transcribed seq=35 len=203
2025-08-24 02:07:48,749 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:48,749 - INFO - WorkerThread-1 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 02:07:49,856 - INFO - WorkerThread-0 - 转写完成: 037.wav, 文本长度: 77
2025-08-24 02:07:49,857 - INFO - WorkerThread-0 - transcribed seq=37 len=77
2025-08-24 02:07:49,857 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:49,858 - INFO - WorkerThread-0 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 02:07:49,951 - INFO - WorkerThread-1 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 02:07:49,953 - INFO - WorkerThread-1 - transcribed seq=38 len=149
2025-08-24 02:07:49,953 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:49,954 - INFO - WorkerThread-1 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 02:07:50,234 - INFO - MergeThread - 合并完成: archive\full_011_to_038.txt
2025-08-24 02:07:50,759 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:07:51,131 - INFO - WorkerThread-1 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 02:07:51,132 - INFO - WorkerThread-1 - transcribed seq=40 len=194
2025-08-24 02:07:51,132 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:51,133 - INFO - WorkerThread-1 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 02:07:51,245 - INFO - WorkerThread-0 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 02:07:51,245 - INFO - WorkerThread-0 - transcribed seq=39 len=199
2025-08-24 02:07:51,246 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:51,247 - INFO - WorkerThread-0 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 02:07:52,409 - INFO - WorkerThread-1 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 02:07:52,410 - INFO - WorkerThread-1 - transcribed seq=41 len=232
2025-08-24 02:07:52,508 - INFO - WorkerThread-0 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 02:07:52,509 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:52,509 - INFO - WorkerThread-0 - transcribed seq=42 len=203
2025-08-24 02:07:52,509 - INFO - WorkerThread-1 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 02:07:52,509 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:52,513 - INFO - WorkerThread-0 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 02:07:53,500 - INFO - WorkerThread-0 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 02:07:53,501 - INFO - WorkerThread-0 - transcribed seq=44 len=199
2025-08-24 02:07:53,501 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:53,502 - INFO - WorkerThread-0 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 02:07:54,135 - INFO - WorkerThread-1 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 02:07:54,136 - INFO - WorkerThread-1 - transcribed seq=43 len=202
2025-08-24 02:07:54,136 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:54,138 - INFO - WorkerThread-1 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 02:07:54,596 - INFO - WorkerThread-0 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 02:07:54,596 - INFO - WorkerThread-0 - transcribed seq=45 len=207
2025-08-24 02:07:54,597 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:54,597 - INFO - WorkerThread-0 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 02:07:55,318 - INFO - WorkerThread-1 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 02:07:55,319 - INFO - WorkerThread-1 - transcribed seq=46 len=212
2025-08-24 02:07:55,319 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:55,319 - INFO - WorkerThread-1 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 02:07:55,861 - INFO - WorkerThread-0 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 02:07:55,862 - INFO - WorkerThread-0 - transcribed seq=47 len=173
2025-08-24 02:07:55,862 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:55,863 - INFO - WorkerThread-0 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 02:07:56,599 - INFO - WorkerThread-1 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 02:07:56,600 - INFO - WorkerThread-1 - transcribed seq=48 len=236
2025-08-24 02:07:56,600 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:56,601 - INFO - WorkerThread-1 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 02:07:57,108 - INFO - WorkerThread-0 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 02:07:57,108 - INFO - WorkerThread-0 - transcribed seq=49 len=185
2025-08-24 02:07:57,109 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:57,109 - INFO - WorkerThread-0 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 02:07:57,837 - INFO - WorkerThread-1 - 转写完成: 050.wav, 文本长度: 185
2025-08-24 02:07:57,837 - INFO - WorkerThread-1 - transcribed seq=50 len=185
2025-08-24 02:07:57,837 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:57,838 - INFO - WorkerThread-1 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 02:07:58,367 - INFO - WorkerThread-0 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 02:07:58,367 - INFO - WorkerThread-0 - transcribed seq=51 len=163
2025-08-24 02:07:58,368 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:58,368 - INFO - WorkerThread-0 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 02:07:59,040 - INFO - WorkerThread-1 - 转写完成: 052.wav, 文本长度: 167
2025-08-24 02:07:59,041 - INFO - WorkerThread-1 - transcribed seq=52 len=167
2025-08-24 02:07:59,042 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:07:59,042 - INFO - WorkerThread-1 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 02:07:59,550 - INFO - WorkerThread-0 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 02:07:59,550 - INFO - WorkerThread-0 - transcribed seq=53 len=176
2025-08-24 02:07:59,853 - INFO - WorkerThread-1 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 02:07:59,854 - INFO - WorkerThread-1 - transcribed seq=54 len=121
2025-08-24 02:08:05,772 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.810511 seconds
2025-08-24 02:08:08,446 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:08:10,238 - INFO - MergeThread - 合并完成: archive\full_039_to_054.txt
2025-08-24 02:08:23,452 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:08:23,483 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:08:25,233 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:08:40,246 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.447429 seconds
2025-08-24 02:08:42,499 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:08:57,515 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.935271 seconds
2025-08-24 02:09:00,152 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:09:15,162 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:09:15,174 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:09:16,671 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:09:31,685 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.436091 seconds
2025-08-24 02:09:33,741 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:09:48,748 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.898766 seconds
2025-08-24 02:09:51,584 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:10:06,593 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:10:06,613 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:10:06,614 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:10:06,615 - INFO - PolishProcessor - 润色完成: full_000_to_010.txt -> polished_full_000_to_010.txt (耗时: 156.01秒)
2025-08-24 02:10:07,628 - INFO - PolishProcessor - 发现 2 个待处理文件
2025-08-24 02:10:07,630 - INFO - PolishProcessor - 开始处理文件: full_011_to_038.txt
2025-08-24 02:10:09,530 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:10:24,538 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.402025 seconds
2025-08-24 02:10:26,843 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:10:41,859 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.924172 seconds
2025-08-24 02:10:44,657 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:10:59,661 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:10:59,692 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:11:01,593 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:11:16,608 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.440425 seconds
2025-08-24 02:11:19,106 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:11:19,851 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 02:11:19,853 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 02:13:09,852 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 02:13:10,777 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 02:13:10,777 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 02:13:10,778 - INFO - MainThread - 启动语音转写系统...
2025-08-24 02:13:10,780 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:10,780 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 02:13:10,780 - INFO - MainThread - SystemManager started
2025-08-24 02:13:10,781 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:10,781 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 02:13:10,782 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 02:13:10,783 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 02:13:10,783 - INFO - MainThread - 润色处理器已启动
2025-08-24 02:13:16,371 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 02:13:18,323 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:13:18,327 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:13:19,330 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 02:13:19,331 - INFO - WorkerThread-1 - excludes: None
2025-08-24 02:13:19,690 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:13:21,069 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:21,070 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 02:13:21,294 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 02:13:22,679 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:13:22,684 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:13:23,406 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 02:13:23,407 - INFO - WorkerThread-0 - excludes: None
2025-08-24 02:13:23,735 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:13:26,034 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:26,035 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 02:13:29,395 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 02:13:29,395 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 02:13:29,395 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:29,414 - INFO - WorkerThread-1 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 02:13:29,548 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 02:13:29,549 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 02:13:29,557 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:29,558 - INFO - WorkerThread-0 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 02:13:30,642 - INFO - WorkerThread-1 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 02:13:30,643 - INFO - WorkerThread-1 - transcribed seq=2 len=66
2025-08-24 02:13:30,644 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:30,644 - INFO - WorkerThread-1 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 02:13:30,749 - INFO - WorkerThread-0 - 转写完成: 003.wav, 文本长度: 78
2025-08-24 02:13:30,753 - INFO - WorkerThread-0 - transcribed seq=3 len=78
2025-08-24 02:13:30,754 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:30,754 - INFO - WorkerThread-0 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 02:13:31,846 - INFO - WorkerThread-1 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 02:13:31,846 - WARNING - WorkerThread-1 - empty transcript, moved to failed handled in job
2025-08-24 02:13:31,846 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:31,848 - INFO - WorkerThread-1 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 02:13:31,954 - INFO - WorkerThread-0 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 02:13:31,955 - INFO - WorkerThread-0 - transcribed seq=5 len=130
2025-08-24 02:13:31,956 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:31,956 - INFO - WorkerThread-0 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 02:13:32,977 - INFO - WorkerThread-1 - 转写完成: 006.wav, 文本长度: 246
2025-08-24 02:13:32,977 - INFO - WorkerThread-1 - transcribed seq=6 len=246
2025-08-24 02:13:32,978 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:32,978 - INFO - WorkerThread-1 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 02:13:33,192 - INFO - WorkerThread-0 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 02:13:33,193 - INFO - WorkerThread-0 - transcribed seq=7 len=234
2025-08-24 02:13:33,193 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:33,194 - INFO - WorkerThread-0 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 02:13:34,202 - INFO - WorkerThread-1 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 02:13:34,203 - INFO - WorkerThread-1 - transcribed seq=8 len=195
2025-08-24 02:13:34,203 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:34,203 - INFO - WorkerThread-1 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 02:13:34,376 - INFO - WorkerThread-0 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 02:13:34,377 - INFO - WorkerThread-0 - transcribed seq=9 len=222
2025-08-24 02:13:34,377 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:34,378 - INFO - WorkerThread-0 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 02:13:35,510 - INFO - WorkerThread-1 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 02:13:35,513 - INFO - WorkerThread-1 - transcribed seq=10 len=230
2025-08-24 02:13:35,513 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:35,513 - INFO - WorkerThread-1 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 02:13:35,607 - INFO - WorkerThread-0 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 02:13:35,608 - INFO - WorkerThread-0 - transcribed seq=11 len=225
2025-08-24 02:13:35,608 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:35,608 - INFO - WorkerThread-0 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 02:13:36,758 - INFO - WorkerThread-0 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 02:13:36,759 - INFO - WorkerThread-0 - transcribed seq=13 len=212
2025-08-24 02:13:36,760 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:36,760 - INFO - WorkerThread-0 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 02:13:36,889 - INFO - WorkerThread-1 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 02:13:36,889 - INFO - WorkerThread-1 - transcribed seq=12 len=111
2025-08-24 02:13:36,890 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:36,891 - INFO - WorkerThread-1 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 02:13:37,949 - INFO - WorkerThread-0 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 02:13:37,950 - INFO - WorkerThread-0 - transcribed seq=14 len=190
2025-08-24 02:13:37,950 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:37,950 - INFO - WorkerThread-0 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 02:13:38,134 - INFO - WorkerThread-1 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 02:13:38,134 - INFO - WorkerThread-1 - transcribed seq=15 len=162
2025-08-24 02:13:38,135 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:38,135 - INFO - WorkerThread-1 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 02:13:39,225 - INFO - WorkerThread-0 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 02:13:39,226 - INFO - WorkerThread-0 - transcribed seq=16 len=134
2025-08-24 02:13:39,227 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:39,229 - INFO - WorkerThread-0 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 02:13:39,365 - INFO - WorkerThread-1 - 转写完成: 017.wav, 文本长度: 169
2025-08-24 02:13:39,365 - INFO - WorkerThread-1 - transcribed seq=17 len=169
2025-08-24 02:13:39,370 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:39,371 - INFO - WorkerThread-1 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 02:13:40,508 - INFO - WorkerThread-0 - 转写完成: 018.wav, 文本长度: 245
2025-08-24 02:13:40,508 - INFO - WorkerThread-0 - transcribed seq=18 len=245
2025-08-24 02:13:40,508 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:40,508 - INFO - WorkerThread-0 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 02:13:40,618 - INFO - WorkerThread-1 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 02:13:40,623 - INFO - WorkerThread-1 - transcribed seq=19 len=215
2025-08-24 02:13:40,624 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:40,624 - INFO - WorkerThread-1 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 02:13:41,747 - INFO - WorkerThread-0 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 02:13:41,747 - INFO - WorkerThread-0 - transcribed seq=20 len=214
2025-08-24 02:13:41,748 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:41,748 - INFO - WorkerThread-0 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 02:13:41,855 - INFO - WorkerThread-1 - 转写完成: 021.wav, 文本长度: 218
2025-08-24 02:13:41,856 - INFO - WorkerThread-1 - transcribed seq=21 len=218
2025-08-24 02:13:41,856 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:41,857 - INFO - WorkerThread-1 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 02:13:42,928 - INFO - WorkerThread-0 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 02:13:42,929 - INFO - WorkerThread-0 - transcribed seq=22 len=183
2025-08-24 02:13:42,929 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:42,931 - INFO - WorkerThread-0 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 02:13:43,112 - INFO - WorkerThread-1 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 02:13:43,113 - INFO - WorkerThread-1 - transcribed seq=23 len=223
2025-08-24 02:13:43,113 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:43,114 - INFO - WorkerThread-1 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 02:13:43,989 - INFO - WorkerThread-0 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 02:13:43,990 - INFO - WorkerThread-0 - transcribed seq=24 len=229
2025-08-24 02:13:43,990 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:43,991 - INFO - WorkerThread-0 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 02:13:44,643 - INFO - WorkerThread-1 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 02:13:44,644 - INFO - WorkerThread-1 - transcribed seq=25 len=198
2025-08-24 02:13:44,644 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:44,645 - INFO - WorkerThread-1 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 02:13:44,979 - INFO - WorkerThread-0 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 02:13:44,980 - INFO - WorkerThread-0 - transcribed seq=26 len=184
2025-08-24 02:13:44,980 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:44,981 - INFO - WorkerThread-0 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 02:13:45,911 - INFO - WorkerThread-1 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 02:13:45,911 - INFO - WorkerThread-1 - transcribed seq=27 len=195
2025-08-24 02:13:45,912 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:45,912 - INFO - WorkerThread-1 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 02:13:46,091 - INFO - WorkerThread-0 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 02:13:46,091 - INFO - WorkerThread-0 - transcribed seq=28 len=222
2025-08-24 02:13:46,092 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:46,092 - INFO - WorkerThread-0 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 02:13:47,170 - INFO - WorkerThread-1 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 02:13:47,170 - INFO - WorkerThread-1 - transcribed seq=29 len=164
2025-08-24 02:13:47,172 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:47,173 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 02:13:47,273 - INFO - WorkerThread-0 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 02:13:47,274 - INFO - WorkerThread-0 - transcribed seq=30 len=180
2025-08-24 02:13:47,274 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:47,275 - INFO - WorkerThread-0 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 02:13:48,410 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 02:13:48,410 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 02:13:48,410 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:48,411 - INFO - WorkerThread-1 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 02:13:48,523 - INFO - WorkerThread-0 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 02:13:48,523 - INFO - WorkerThread-0 - transcribed seq=32 len=211
2025-08-24 02:13:48,524 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:48,525 - INFO - WorkerThread-0 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 02:13:49,069 - INFO - MergeThread - 合并完成: archive\full_000_to_032.txt
2025-08-24 02:13:49,304 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:13:49,304 - INFO - PolishProcessor - 开始处理文件: full_000_to_032.txt
2025-08-24 02:13:49,775 - INFO - WorkerThread-0 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 02:13:49,777 - INFO - WorkerThread-0 - transcribed seq=34 len=130
2025-08-24 02:13:49,778 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:49,778 - INFO - WorkerThread-0 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 02:13:49,921 - INFO - WorkerThread-1 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 02:13:49,922 - INFO - WorkerThread-1 - transcribed seq=33 len=222
2025-08-24 02:13:49,922 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:49,927 - INFO - WorkerThread-1 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 02:13:51,082 - INFO - WorkerThread-1 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 02:13:51,083 - INFO - WorkerThread-1 - transcribed seq=36 len=127
2025-08-24 02:13:51,105 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:51,105 - INFO - WorkerThread-1 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 02:13:51,242 - INFO - WorkerThread-0 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 02:13:51,243 - INFO - WorkerThread-0 - transcribed seq=35 len=203
2025-08-24 02:13:51,243 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:51,244 - INFO - WorkerThread-0 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 02:13:52,421 - INFO - WorkerThread-0 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 02:13:52,421 - INFO - WorkerThread-0 - transcribed seq=38 len=149
2025-08-24 02:13:52,421 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:52,422 - INFO - WorkerThread-0 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 02:13:52,535 - INFO - WorkerThread-1 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 02:13:52,535 - INFO - WorkerThread-1 - transcribed seq=37 len=78
2025-08-24 02:13:52,536 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:52,539 - INFO - WorkerThread-1 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 02:13:53,110 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:13:53,533 - INFO - WorkerThread-1 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 02:13:53,534 - INFO - WorkerThread-1 - transcribed seq=40 len=194
2025-08-24 02:13:53,536 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:53,537 - INFO - WorkerThread-1 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 02:13:54,299 - INFO - WorkerThread-0 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 02:13:54,300 - INFO - WorkerThread-0 - transcribed seq=39 len=199
2025-08-24 02:13:54,301 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:54,302 - INFO - WorkerThread-0 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 02:13:54,452 - INFO - WorkerThread-1 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 02:13:54,453 - INFO - WorkerThread-1 - transcribed seq=41 len=232
2025-08-24 02:13:54,453 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:54,454 - INFO - WorkerThread-1 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 02:13:55,609 - INFO - WorkerThread-1 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 02:13:55,610 - INFO - WorkerThread-1 - transcribed seq=43 len=202
2025-08-24 02:13:55,611 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:55,612 - INFO - WorkerThread-1 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 02:13:55,731 - INFO - WorkerThread-0 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 02:13:55,732 - INFO - WorkerThread-0 - transcribed seq=42 len=203
2025-08-24 02:13:55,732 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:55,732 - INFO - WorkerThread-0 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 02:13:57,010 - INFO - WorkerThread-1 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 02:13:57,012 - INFO - WorkerThread-1 - transcribed seq=44 len=199
2025-08-24 02:13:57,014 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:57,015 - INFO - WorkerThread-1 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 02:13:57,267 - INFO - WorkerThread-0 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 02:13:57,269 - INFO - WorkerThread-0 - transcribed seq=45 len=207
2025-08-24 02:13:57,270 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:57,270 - INFO - WorkerThread-0 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 02:13:58,766 - INFO - WorkerThread-1 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 02:13:58,807 - INFO - WorkerThread-1 - transcribed seq=46 len=212
2025-08-24 02:13:58,808 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:58,809 - INFO - WorkerThread-1 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 02:13:59,454 - INFO - WorkerThread-0 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 02:13:59,605 - INFO - WorkerThread-0 - transcribed seq=47 len=173
2025-08-24 02:13:59,607 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:13:59,608 - INFO - WorkerThread-0 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 02:14:01,572 - INFO - WorkerThread-1 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 02:14:01,597 - INFO - WorkerThread-1 - transcribed seq=48 len=236
2025-08-24 02:14:01,599 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:14:01,599 - INFO - WorkerThread-1 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 02:14:01,820 - INFO - WorkerThread-0 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 02:14:01,821 - INFO - WorkerThread-0 - transcribed seq=49 len=185
2025-08-24 02:14:01,822 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:14:01,823 - INFO - WorkerThread-0 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 02:14:03,226 - INFO - WorkerThread-1 - 转写完成: 050.wav, 文本长度: 185
2025-08-24 02:14:03,227 - INFO - WorkerThread-1 - transcribed seq=50 len=185
2025-08-24 02:14:03,229 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:14:03,231 - INFO - WorkerThread-1 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 02:14:03,465 - INFO - WorkerThread-0 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 02:14:03,465 - INFO - WorkerThread-0 - transcribed seq=51 len=163
2025-08-24 02:14:03,467 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:14:03,468 - INFO - WorkerThread-0 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 02:14:05,245 - INFO - WorkerThread-0 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 02:14:05,245 - INFO - WorkerThread-0 - transcribed seq=53 len=176
2025-08-24 02:14:05,247 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:14:05,247 - INFO - WorkerThread-0 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 02:14:05,484 - INFO - WorkerThread-1 - 转写完成: 052.wav, 文本长度: 166
2025-08-24 02:14:05,485 - INFO - WorkerThread-1 - transcribed seq=52 len=166
2025-08-24 02:14:06,368 - INFO - WorkerThread-0 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 02:14:06,369 - INFO - WorkerThread-0 - transcribed seq=54 len=121
2025-08-24 02:14:08,116 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.394447 seconds
2025-08-24 02:14:09,083 - INFO - MergeThread - 合并完成: archive\full_033_to_054.txt
2025-08-24 02:14:10,408 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:14:25,413 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.810511 seconds
2025-08-24 02:14:28,186 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:14:43,201 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:14:43,246 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:14:45,158 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:14:48,289 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 02:14:48,290 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 02:14:53,304 - INFO - MainThread - 润色处理器已停止
2025-08-24 02:14:53,428 - INFO - MainThread - SystemManager stopped
2025-08-24 02:14:53,429 - INFO - MainThread - 系统已安全关闭
2025-08-24 02:18:21,701 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 02:18:22,584 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 02:18:22,584 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 02:18:22,585 - INFO - MainThread - 启动语音转写系统...
2025-08-24 02:18:22,586 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:22,587 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 02:18:22,587 - INFO - MainThread - SystemManager started
2025-08-24 02:18:22,587 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:22,588 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 02:18:22,588 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 02:18:22,590 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 02:18:22,590 - INFO - MainThread - 润色处理器已启动
2025-08-24 02:18:22,591 - INFO - PolishProcessor - 发现 2 个待处理文件
2025-08-24 02:18:22,592 - INFO - PolishProcessor - 开始处理文件: full_000_to_032.txt
2025-08-24 02:18:22,592 - INFO - PolishProcessor - 检测到长文本 (5886 字符)，启用分段处理
2025-08-24 02:18:22,593 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:18:22,593 - INFO - PolishProcessor - 处理第 1 个分段 (5887 字符, 1/1 句子)
2025-08-24 02:18:25,186 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:18:27,489 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 02:18:29,143 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:18:29,148 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:18:29,844 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 02:18:29,844 - INFO - WorkerThread-0 - excludes: None
2025-08-24 02:18:30,227 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:18:31,574 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:31,575 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 02:18:32,368 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 02:18:33,761 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:18:33,766 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:18:34,445 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 02:18:34,445 - INFO - WorkerThread-1 - excludes: None
2025-08-24 02:18:34,849 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:18:38,153 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:38,154 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 02:18:38,327 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 02:18:38,328 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 02:18:38,328 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:38,349 - INFO - WorkerThread-0 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 02:18:39,463 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 02:18:39,464 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 02:18:39,465 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:39,465 - INFO - WorkerThread-1 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 02:18:39,583 - INFO - WorkerThread-0 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 02:18:39,584 - INFO - WorkerThread-0 - transcribed seq=2 len=66
2025-08-24 02:18:39,584 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:39,585 - INFO - WorkerThread-0 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 02:18:40,212 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.394447 seconds
2025-08-24 02:18:40,686 - INFO - WorkerThread-1 - 转写完成: 003.wav, 文本长度: 78
2025-08-24 02:18:40,687 - INFO - WorkerThread-1 - transcribed seq=3 len=78
2025-08-24 02:18:40,689 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:40,689 - INFO - WorkerThread-1 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 02:18:40,805 - INFO - WorkerThread-0 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 02:18:40,806 - WARNING - WorkerThread-0 - empty transcript, moved to failed handled in job
2025-08-24 02:18:40,807 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:40,808 - INFO - WorkerThread-0 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 02:18:40,939 - INFO - MergeThread - 合并完成: archive\full_000_to_003.txt
2025-08-24 02:18:41,909 - INFO - WorkerThread-0 - 转写完成: 006.wav, 文本长度: 245
2025-08-24 02:18:41,910 - INFO - WorkerThread-0 - transcribed seq=6 len=245
2025-08-24 02:18:41,910 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:41,910 - INFO - WorkerThread-0 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 02:18:42,020 - INFO - WorkerThread-1 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 02:18:42,020 - INFO - WorkerThread-1 - transcribed seq=5 len=130
2025-08-24 02:18:42,021 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:42,021 - INFO - WorkerThread-1 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 02:18:42,822 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:18:43,098 - INFO - WorkerThread-1 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 02:18:43,099 - INFO - WorkerThread-1 - transcribed seq=8 len=195
2025-08-24 02:18:43,099 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:43,100 - INFO - WorkerThread-1 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 02:18:43,263 - INFO - WorkerThread-0 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 02:18:43,264 - INFO - WorkerThread-0 - transcribed seq=7 len=234
2025-08-24 02:18:43,265 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:43,265 - INFO - WorkerThread-0 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 02:18:44,200 - INFO - WorkerThread-1 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 02:18:44,202 - INFO - WorkerThread-1 - transcribed seq=9 len=222
2025-08-24 02:18:44,203 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:44,203 - INFO - WorkerThread-1 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 02:18:44,747 - INFO - WorkerThread-0 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 02:18:44,748 - INFO - WorkerThread-0 - transcribed seq=10 len=230
2025-08-24 02:18:44,749 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:44,749 - INFO - WorkerThread-0 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 02:18:45,408 - INFO - WorkerThread-1 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 02:18:45,408 - INFO - WorkerThread-1 - transcribed seq=11 len=225
2025-08-24 02:18:45,408 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:45,409 - INFO - WorkerThread-1 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 02:18:45,907 - INFO - WorkerThread-0 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 02:18:45,908 - INFO - WorkerThread-0 - transcribed seq=12 len=111
2025-08-24 02:18:45,908 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:45,909 - INFO - WorkerThread-0 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 02:18:46,534 - INFO - WorkerThread-1 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 02:18:46,534 - INFO - WorkerThread-1 - transcribed seq=13 len=212
2025-08-24 02:18:46,535 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:46,535 - INFO - WorkerThread-1 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 02:18:47,111 - INFO - WorkerThread-0 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 02:18:47,112 - INFO - WorkerThread-0 - transcribed seq=14 len=190
2025-08-24 02:18:47,113 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:47,113 - INFO - WorkerThread-0 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 02:18:47,782 - INFO - WorkerThread-1 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 02:18:47,783 - INFO - WorkerThread-1 - transcribed seq=15 len=162
2025-08-24 02:18:47,784 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:47,785 - INFO - WorkerThread-1 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 02:18:48,346 - INFO - WorkerThread-0 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 02:18:48,346 - INFO - WorkerThread-0 - transcribed seq=16 len=134
2025-08-24 02:18:48,347 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:48,348 - INFO - WorkerThread-0 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 02:18:49,030 - INFO - WorkerThread-1 - 转写完成: 017.wav, 文本长度: 169
2025-08-24 02:18:49,030 - INFO - WorkerThread-1 - transcribed seq=17 len=169
2025-08-24 02:18:49,032 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:49,032 - INFO - WorkerThread-1 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 02:18:49,554 - INFO - WorkerThread-0 - 转写完成: 018.wav, 文本长度: 248
2025-08-24 02:18:49,555 - INFO - WorkerThread-0 - transcribed seq=18 len=248
2025-08-24 02:18:49,555 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:49,555 - INFO - WorkerThread-0 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 02:18:50,267 - INFO - WorkerThread-1 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 02:18:50,267 - INFO - WorkerThread-1 - transcribed seq=19 len=215
2025-08-24 02:18:50,267 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:50,268 - INFO - WorkerThread-1 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 02:18:50,805 - INFO - WorkerThread-0 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 02:18:50,806 - INFO - WorkerThread-0 - transcribed seq=20 len=214
2025-08-24 02:18:50,807 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:50,807 - INFO - WorkerThread-0 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 02:18:51,525 - INFO - WorkerThread-1 - 转写完成: 021.wav, 文本长度: 219
2025-08-24 02:18:51,526 - INFO - WorkerThread-1 - transcribed seq=21 len=219
2025-08-24 02:18:51,526 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:51,527 - INFO - WorkerThread-1 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 02:18:52,088 - INFO - WorkerThread-0 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 02:18:52,088 - INFO - WorkerThread-0 - transcribed seq=22 len=183
2025-08-24 02:18:52,089 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:52,090 - INFO - WorkerThread-0 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 02:18:52,807 - INFO - WorkerThread-1 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 02:18:52,808 - INFO - WorkerThread-1 - transcribed seq=23 len=223
2025-08-24 02:18:52,808 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:52,809 - INFO - WorkerThread-1 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 02:18:53,286 - INFO - WorkerThread-0 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 02:18:53,287 - INFO - WorkerThread-0 - transcribed seq=24 len=229
2025-08-24 02:18:53,288 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:53,288 - INFO - WorkerThread-0 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 02:18:54,128 - INFO - WorkerThread-1 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 02:18:54,129 - INFO - WorkerThread-1 - transcribed seq=25 len=198
2025-08-24 02:18:54,130 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:54,131 - INFO - WorkerThread-1 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 02:18:54,553 - INFO - WorkerThread-0 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 02:18:54,554 - INFO - WorkerThread-0 - transcribed seq=26 len=184
2025-08-24 02:18:54,554 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:54,555 - INFO - WorkerThread-0 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 02:18:55,403 - INFO - WorkerThread-1 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 02:18:55,403 - INFO - WorkerThread-1 - transcribed seq=27 len=195
2025-08-24 02:18:55,404 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:55,404 - INFO - WorkerThread-1 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 02:18:55,722 - INFO - WorkerThread-0 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 02:18:55,722 - INFO - WorkerThread-0 - transcribed seq=28 len=222
2025-08-24 02:18:55,723 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:55,724 - INFO - WorkerThread-0 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 02:18:56,740 - INFO - WorkerThread-1 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 02:18:56,740 - INFO - WorkerThread-1 - transcribed seq=29 len=164
2025-08-24 02:18:56,740 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:56,740 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 02:18:56,904 - INFO - WorkerThread-0 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 02:18:56,904 - INFO - WorkerThread-0 - transcribed seq=30 len=180
2025-08-24 02:18:56,905 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:56,906 - INFO - WorkerThread-0 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 02:18:57,822 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.810511 seconds
2025-08-24 02:18:58,039 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 02:18:58,040 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 02:18:58,040 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:58,041 - INFO - WorkerThread-1 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 02:18:58,149 - INFO - WorkerThread-0 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 02:18:58,150 - INFO - WorkerThread-0 - transcribed seq=32 len=211
2025-08-24 02:18:58,150 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:58,151 - INFO - WorkerThread-0 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 02:18:59,373 - INFO - WorkerThread-1 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 02:18:59,373 - INFO - WorkerThread-1 - transcribed seq=33 len=222
2025-08-24 02:18:59,374 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:59,375 - INFO - WorkerThread-1 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 02:18:59,519 - INFO - WorkerThread-0 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 02:18:59,520 - INFO - WorkerThread-0 - transcribed seq=34 len=130
2025-08-24 02:18:59,520 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:18:59,521 - INFO - WorkerThread-0 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 02:19:00,658 - INFO - WorkerThread-1 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 02:19:00,659 - INFO - WorkerThread-1 - transcribed seq=35 len=203
2025-08-24 02:19:00,659 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:00,660 - INFO - WorkerThread-1 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 02:19:00,796 - INFO - WorkerThread-0 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 02:19:00,797 - INFO - WorkerThread-0 - transcribed seq=36 len=127
2025-08-24 02:19:00,797 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:00,797 - INFO - WorkerThread-0 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 02:19:00,950 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:19:00,955 - INFO - MergeThread - 合并完成: archive\full_005_to_036.txt
2025-08-24 02:19:01,989 - INFO - WorkerThread-1 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 02:19:01,990 - INFO - WorkerThread-1 - transcribed seq=37 len=78
2025-08-24 02:19:01,990 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:01,991 - INFO - WorkerThread-1 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 02:19:02,089 - INFO - WorkerThread-0 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 02:19:02,089 - INFO - WorkerThread-0 - transcribed seq=38 len=149
2025-08-24 02:19:02,090 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:02,091 - INFO - WorkerThread-0 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 02:19:03,320 - INFO - WorkerThread-1 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 02:19:03,321 - INFO - WorkerThread-1 - transcribed seq=39 len=199
2025-08-24 02:19:03,321 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:03,322 - INFO - WorkerThread-1 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 02:19:03,449 - INFO - WorkerThread-0 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 02:19:03,451 - INFO - WorkerThread-0 - transcribed seq=40 len=194
2025-08-24 02:19:03,453 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:03,454 - INFO - WorkerThread-0 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 02:19:04,678 - INFO - WorkerThread-1 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 02:19:04,679 - INFO - WorkerThread-1 - transcribed seq=41 len=232
2025-08-24 02:19:04,680 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:04,681 - INFO - WorkerThread-1 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 02:19:04,830 - INFO - WorkerThread-0 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 02:19:04,831 - INFO - WorkerThread-0 - transcribed seq=42 len=203
2025-08-24 02:19:04,834 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:04,835 - INFO - WorkerThread-0 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 02:19:06,271 - INFO - WorkerThread-1 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 02:19:06,272 - INFO - WorkerThread-1 - transcribed seq=43 len=202
2025-08-24 02:19:06,273 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:06,275 - INFO - WorkerThread-1 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 02:19:06,450 - INFO - WorkerThread-0 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 02:19:06,451 - INFO - WorkerThread-0 - transcribed seq=44 len=199
2025-08-24 02:19:06,452 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:06,453 - INFO - WorkerThread-0 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 02:19:08,055 - INFO - WorkerThread-1 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 02:19:08,057 - INFO - WorkerThread-1 - transcribed seq=45 len=207
2025-08-24 02:19:08,204 - INFO - WorkerThread-0 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 02:19:08,205 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:08,205 - INFO - WorkerThread-0 - transcribed seq=46 len=212
2025-08-24 02:19:08,206 - INFO - WorkerThread-1 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 02:19:08,207 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:08,216 - INFO - WorkerThread-0 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 02:19:09,806 - INFO - WorkerThread-1 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 02:19:09,807 - INFO - WorkerThread-1 - transcribed seq=47 len=173
2025-08-24 02:19:09,808 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:09,809 - INFO - WorkerThread-1 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 02:19:09,999 - INFO - WorkerThread-0 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 02:19:09,999 - INFO - WorkerThread-0 - transcribed seq=48 len=236
2025-08-24 02:19:10,001 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:10,002 - INFO - WorkerThread-0 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 02:19:11,514 - INFO - WorkerThread-1 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 02:19:11,515 - INFO - WorkerThread-1 - transcribed seq=49 len=185
2025-08-24 02:19:11,517 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:11,518 - INFO - WorkerThread-1 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 02:19:11,658 - INFO - WorkerThread-0 - 转写完成: 050.wav, 文本长度: 186
2025-08-24 02:19:11,659 - INFO - WorkerThread-0 - transcribed seq=50 len=186
2025-08-24 02:19:11,661 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:11,662 - INFO - WorkerThread-0 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 02:19:12,853 - INFO - WorkerThread-0 - 转写完成: 052.wav, 文本长度: 166
2025-08-24 02:19:12,854 - INFO - WorkerThread-0 - transcribed seq=52 len=166
2025-08-24 02:19:12,854 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:12,855 - INFO - WorkerThread-0 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 02:19:12,979 - INFO - WorkerThread-1 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 02:19:12,981 - INFO - WorkerThread-1 - transcribed seq=51 len=163
2025-08-24 02:19:12,982 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:19:12,983 - INFO - WorkerThread-1 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 02:19:14,073 - INFO - WorkerThread-0 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 02:19:14,073 - INFO - WorkerThread-0 - transcribed seq=53 len=176
2025-08-24 02:19:14,216 - INFO - WorkerThread-1 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 02:19:14,217 - INFO - WorkerThread-1 - transcribed seq=54 len=121
2025-08-24 02:19:15,958 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:19:16,005 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:19:17,875 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:19:20,979 - INFO - MergeThread - 合并完成: archive\full_037_to_054.txt
2025-08-24 02:19:32,878 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.447429 seconds
2025-08-24 02:19:35,323 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:19:39,186 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.935271 seconds
2025-08-24 02:19:42,053 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:19:57,062 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:19:57,092 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:19:58,919 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:20:13,926 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.436091 seconds
2025-08-24 02:20:16,383 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:20:31,390 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.898766 seconds
2025-08-24 02:20:34,095 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:20:49,099 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:20:49,129 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:20:49,131 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:20:49,132 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:20:49,133 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:20:49,135 - INFO - PolishProcessor - 润色完成: full_000_to_032.txt -> polished_full_000_to_032.txt (耗时: 146.54秒)
2025-08-24 02:20:50,141 - INFO - PolishProcessor - 开始处理文件: full_033_to_054.txt
2025-08-24 02:20:50,144 - INFO - PolishProcessor - 检测到长文本 (3983 字符)，启用分段处理
2025-08-24 02:20:50,144 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:20:50,145 - INFO - PolishProcessor - 处理第 1 个分段 (3984 字符, 1/1 句子)
2025-08-24 02:20:52,079 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:21:07,089 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.402025 seconds
2025-08-24 02:21:09,319 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:21:24,334 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.924172 seconds
2025-08-24 02:21:27,145 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:21:42,158 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:21:42,174 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:21:43,661 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:21:58,671 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.440425 seconds
2025-08-24 02:22:01,035 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:22:16,042 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.854154 seconds
2025-08-24 02:22:18,848 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:22:33,852 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:22:33,882 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:22:35,846 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:22:50,855 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.386486 seconds
2025-08-24 02:22:53,162 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:23:08,165 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.873828 seconds
2025-08-24 02:23:10,552 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:23:25,559 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:23:25,590 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:23:25,591 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:23:25,592 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:23:25,592 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:23:25,594 - INFO - PolishProcessor - 润色完成: full_033_to_054.txt -> polished_full_033_to_054.txt (耗时: 155.45秒)
2025-08-24 02:23:26,598 - INFO - PolishProcessor - 发现 3 个待处理文件
2025-08-24 02:23:26,599 - INFO - PolishProcessor - 开始处理文件: full_000_to_003.txt
2025-08-24 02:23:28,016 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:23:43,032 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.464770 seconds
2025-08-24 02:23:44,876 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:23:59,889 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.811049 seconds
2025-08-24 02:24:02,175 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:24:17,178 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:24:17,208 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:24:18,776 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:24:33,778 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.422704 seconds
2025-08-24 02:24:35,761 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:24:50,768 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.937373 seconds
2025-08-24 02:24:53,124 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:25:08,140 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:25:08,171 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:25:09,609 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:25:13,238 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 02:25:13,238 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 02:26:15,045 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 02:26:15,433 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 02:26:15,434 - INFO - MainThread - 加载已处理文件列表: 2 个文件
2025-08-24 02:26:15,435 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 02:26:15,436 - INFO - MainThread - 启动语音转写系统...
2025-08-24 02:26:15,438 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:15,438 - INFO - MainThread - SystemManager started
2025-08-24 02:26:15,439 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:15,439 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 02:26:15,439 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 02:26:15,439 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 02:26:15,441 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 02:26:15,441 - INFO - MainThread - 润色处理器已启动
2025-08-24 02:26:15,442 - INFO - PolishProcessor - 发现 3 个待处理文件
2025-08-24 02:26:15,443 - INFO - PolishProcessor - 开始处理文件: full_000_to_003.txt
2025-08-24 02:26:16,292 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:26:17,143 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 02:26:18,738 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:26:18,742 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:26:19,215 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 02:26:19,942 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 02:26:19,942 - INFO - WorkerThread-1 - excludes: None
2025-08-24 02:26:20,358 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:26:21,097 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:26:21,101 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:26:21,768 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 02:26:21,768 - INFO - WorkerThread-0 - excludes: None
2025-08-24 02:26:22,014 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:22,015 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 02:26:22,204 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:26:24,857 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:24,858 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 02:26:27,460 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 02:26:27,548 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 02:26:27,548 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 02:26:27,549 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 02:26:27,549 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:27,550 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:27,550 - INFO - WorkerThread-0 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 02:26:27,567 - INFO - WorkerThread-1 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 02:26:28,844 - INFO - WorkerThread-1 - 转写完成: 003.wav, 文本长度: 79
2025-08-24 02:26:28,845 - INFO - WorkerThread-1 - transcribed seq=3 len=79
2025-08-24 02:26:28,846 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:28,847 - INFO - WorkerThread-1 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 02:26:28,980 - INFO - WorkerThread-0 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 02:26:28,980 - INFO - WorkerThread-0 - transcribed seq=2 len=66
2025-08-24 02:26:28,981 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:28,981 - INFO - WorkerThread-0 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 02:26:30,137 - INFO - WorkerThread-1 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 02:26:30,138 - WARNING - WorkerThread-1 - empty transcript, moved to failed handled in job
2025-08-24 02:26:30,139 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:30,139 - INFO - WorkerThread-1 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 02:26:30,291 - INFO - WorkerThread-0 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 02:26:30,292 - INFO - WorkerThread-0 - transcribed seq=5 len=130
2025-08-24 02:26:30,292 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:30,293 - INFO - WorkerThread-0 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 02:26:31,512 - INFO - WorkerThread-1 - 转写完成: 006.wav, 文本长度: 248
2025-08-24 02:26:31,513 - INFO - WorkerThread-1 - transcribed seq=6 len=248
2025-08-24 02:26:31,513 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:31,514 - INFO - WorkerThread-1 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 02:26:31,653 - INFO - WorkerThread-0 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 02:26:31,655 - INFO - WorkerThread-0 - transcribed seq=7 len=234
2025-08-24 02:26:31,655 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:31,656 - INFO - WorkerThread-0 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 02:26:32,851 - INFO - WorkerThread-1 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 02:26:32,852 - INFO - WorkerThread-1 - transcribed seq=8 len=195
2025-08-24 02:26:32,853 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:32,854 - INFO - WorkerThread-1 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 02:26:33,008 - INFO - WorkerThread-0 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 02:26:33,011 - INFO - WorkerThread-0 - transcribed seq=9 len=222
2025-08-24 02:26:33,012 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:33,013 - INFO - WorkerThread-0 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 02:26:34,118 - INFO - WorkerThread-1 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 02:26:34,118 - INFO - WorkerThread-1 - transcribed seq=10 len=230
2025-08-24 02:26:34,119 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:34,119 - INFO - WorkerThread-1 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 02:26:34,293 - INFO - WorkerThread-0 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 02:26:34,294 - INFO - WorkerThread-0 - transcribed seq=11 len=225
2025-08-24 02:26:34,295 - INFO - MergeThread - 合并完成: archive\full_000_to_010.txt
2025-08-24 02:26:34,295 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:34,296 - INFO - WorkerThread-0 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 02:26:34,734 - INFO - PolishProcessor - 润色成功，文本长度: 311 -> 378
2025-08-24 02:26:34,735 - INFO - PolishProcessor - 润色完成: full_000_to_003.txt -> polished_full_000_to_003.txt (耗时: 19.29秒)
2025-08-24 02:26:35,468 - INFO - WorkerThread-1 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 02:26:35,468 - INFO - WorkerThread-1 - transcribed seq=12 len=111
2025-08-24 02:26:35,468 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:35,469 - INFO - WorkerThread-1 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 02:26:35,645 - INFO - WorkerThread-0 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 02:26:35,657 - INFO - WorkerThread-0 - transcribed seq=13 len=212
2025-08-24 02:26:35,706 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:35,707 - INFO - WorkerThread-0 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 02:26:35,742 - INFO - PolishProcessor - 开始处理文件: full_005_to_036.txt
2025-08-24 02:26:35,744 - INFO - PolishProcessor - 检测到长文本 (6263 字符)，启用分段处理
2025-08-24 02:26:35,745 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:26:35,745 - INFO - PolishProcessor - 处理第 1 个分段 (6264 字符, 1/1 句子)
2025-08-24 02:26:35,957 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:26:36,916 - INFO - WorkerThread-1 - 转写完成: 014.wav, 文本长度: 188
2025-08-24 02:26:36,917 - INFO - WorkerThread-1 - transcribed seq=14 len=188
2025-08-24 02:26:36,918 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:36,918 - INFO - WorkerThread-1 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 02:26:37,027 - INFO - WorkerThread-0 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 02:26:37,028 - INFO - WorkerThread-0 - transcribed seq=15 len=162
2025-08-24 02:26:37,028 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:37,028 - INFO - WorkerThread-0 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 02:26:38,197 - INFO - WorkerThread-1 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 02:26:38,198 - INFO - WorkerThread-1 - transcribed seq=16 len=134
2025-08-24 02:26:38,198 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:38,199 - INFO - WorkerThread-1 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 02:26:38,325 - INFO - WorkerThread-0 - 转写完成: 017.wav, 文本长度: 170
2025-08-24 02:26:38,326 - INFO - WorkerThread-0 - transcribed seq=17 len=170
2025-08-24 02:26:38,327 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:38,331 - INFO - WorkerThread-0 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 02:26:39,533 - INFO - WorkerThread-1 - 转写完成: 018.wav, 文本长度: 248
2025-08-24 02:26:39,533 - INFO - WorkerThread-1 - transcribed seq=18 len=248
2025-08-24 02:26:39,534 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:39,534 - INFO - WorkerThread-1 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 02:26:39,660 - INFO - WorkerThread-0 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 02:26:39,661 - INFO - WorkerThread-0 - transcribed seq=19 len=215
2025-08-24 02:26:39,662 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:39,662 - INFO - WorkerThread-0 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 02:26:40,759 - INFO - WorkerThread-1 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 02:26:40,760 - INFO - WorkerThread-1 - transcribed seq=20 len=214
2025-08-24 02:26:40,760 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:40,761 - INFO - WorkerThread-1 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 02:26:41,053 - INFO - WorkerThread-0 - 转写完成: 021.wav, 文本长度: 219
2025-08-24 02:26:41,054 - INFO - WorkerThread-0 - transcribed seq=21 len=219
2025-08-24 02:26:41,054 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:41,055 - INFO - WorkerThread-0 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 02:26:42,073 - INFO - WorkerThread-1 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 02:26:42,074 - INFO - WorkerThread-1 - transcribed seq=22 len=183
2025-08-24 02:26:42,074 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:42,075 - INFO - WorkerThread-1 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 02:26:42,511 - INFO - WorkerThread-0 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 02:26:42,511 - INFO - WorkerThread-0 - transcribed seq=23 len=223
2025-08-24 02:26:42,512 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:42,513 - INFO - WorkerThread-0 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 02:26:43,381 - INFO - WorkerThread-1 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 02:26:43,381 - INFO - WorkerThread-1 - transcribed seq=24 len=229
2025-08-24 02:26:43,382 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:43,382 - INFO - WorkerThread-1 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 02:26:43,606 - INFO - WorkerThread-0 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 02:26:43,607 - INFO - WorkerThread-0 - transcribed seq=25 len=198
2025-08-24 02:26:43,608 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:43,608 - INFO - WorkerThread-0 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 02:26:44,839 - INFO - WorkerThread-0 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 02:26:44,839 - INFO - WorkerThread-0 - transcribed seq=27 len=195
2025-08-24 02:26:44,840 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:44,840 - INFO - WorkerThread-0 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 02:26:44,966 - INFO - WorkerThread-1 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 02:26:44,971 - INFO - WorkerThread-1 - transcribed seq=26 len=184
2025-08-24 02:26:44,972 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:44,972 - INFO - WorkerThread-1 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 02:26:46,138 - INFO - WorkerThread-0 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 02:26:46,139 - INFO - WorkerThread-0 - transcribed seq=28 len=222
2025-08-24 02:26:46,139 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:46,139 - INFO - WorkerThread-0 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 02:26:46,260 - INFO - WorkerThread-1 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 02:26:46,261 - INFO - WorkerThread-1 - transcribed seq=29 len=164
2025-08-24 02:26:46,261 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:46,262 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 02:26:47,486 - INFO - WorkerThread-0 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 02:26:47,488 - INFO - WorkerThread-0 - transcribed seq=30 len=180
2025-08-24 02:26:47,489 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:47,490 - INFO - WorkerThread-0 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 02:26:47,651 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 02:26:47,652 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 02:26:47,653 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:47,654 - INFO - WorkerThread-1 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 02:26:48,721 - INFO - WorkerThread-0 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 02:26:48,722 - INFO - WorkerThread-0 - transcribed seq=32 len=211
2025-08-24 02:26:48,723 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:48,723 - INFO - WorkerThread-0 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 02:26:48,848 - INFO - WorkerThread-1 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 02:26:48,849 - INFO - WorkerThread-1 - transcribed seq=33 len=222
2025-08-24 02:26:48,849 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:48,850 - INFO - WorkerThread-1 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 02:26:50,126 - INFO - WorkerThread-0 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 02:26:50,126 - INFO - WorkerThread-0 - transcribed seq=34 len=130
2025-08-24 02:26:50,127 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:50,128 - INFO - WorkerThread-0 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 02:26:50,245 - INFO - WorkerThread-1 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 02:26:50,246 - INFO - WorkerThread-1 - transcribed seq=35 len=203
2025-08-24 02:26:50,247 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:50,248 - INFO - WorkerThread-1 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 02:26:51,361 - INFO - WorkerThread-0 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 02:26:51,362 - INFO - WorkerThread-0 - transcribed seq=36 len=127
2025-08-24 02:26:51,363 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:51,363 - INFO - WorkerThread-0 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 02:26:51,477 - INFO - WorkerThread-1 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 02:26:51,479 - INFO - WorkerThread-1 - transcribed seq=37 len=78
2025-08-24 02:26:51,483 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:51,484 - INFO - WorkerThread-1 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 02:26:52,760 - INFO - WorkerThread-0 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 02:26:52,760 - INFO - WorkerThread-0 - transcribed seq=38 len=149
2025-08-24 02:26:52,760 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:52,761 - INFO - WorkerThread-0 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 02:26:52,887 - INFO - WorkerThread-1 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 02:26:52,888 - INFO - WorkerThread-1 - transcribed seq=39 len=199
2025-08-24 02:26:52,889 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:52,889 - INFO - WorkerThread-1 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 02:26:54,026 - INFO - WorkerThread-0 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 02:26:54,027 - INFO - WorkerThread-0 - transcribed seq=40 len=194
2025-08-24 02:26:54,028 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:54,028 - INFO - WorkerThread-0 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 02:26:54,262 - INFO - WorkerThread-1 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 02:26:54,262 - INFO - WorkerThread-1 - transcribed seq=41 len=232
2025-08-24 02:26:54,263 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:54,263 - INFO - WorkerThread-1 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 02:26:54,304 - INFO - MergeThread - 合并完成: archive\full_011_to_041.txt
2025-08-24 02:26:55,333 - INFO - WorkerThread-0 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 02:26:55,334 - INFO - WorkerThread-0 - transcribed seq=42 len=203
2025-08-24 02:26:55,334 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:55,335 - INFO - WorkerThread-0 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 02:26:55,474 - INFO - WorkerThread-1 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 02:26:55,474 - INFO - WorkerThread-1 - transcribed seq=43 len=202
2025-08-24 02:26:55,475 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:55,476 - INFO - WorkerThread-1 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 02:26:55,961 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.394447 seconds
2025-08-24 02:26:56,667 - INFO - WorkerThread-0 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 02:26:56,667 - INFO - WorkerThread-0 - transcribed seq=44 len=199
2025-08-24 02:26:56,668 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:56,669 - INFO - WorkerThread-0 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 02:26:56,804 - INFO - WorkerThread-1 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 02:26:56,805 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:26:56,806 - INFO - WorkerThread-1 - transcribed seq=45 len=207
2025-08-24 02:26:56,809 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:56,810 - INFO - WorkerThread-1 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 02:26:58,032 - INFO - WorkerThread-1 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 02:26:58,032 - INFO - WorkerThread-1 - transcribed seq=47 len=173
2025-08-24 02:26:58,033 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:58,034 - INFO - WorkerThread-1 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 02:26:58,157 - INFO - WorkerThread-0 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 02:26:58,161 - INFO - WorkerThread-0 - transcribed seq=46 len=212
2025-08-24 02:26:58,162 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:58,163 - INFO - WorkerThread-0 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 02:26:59,320 - INFO - WorkerThread-1 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 02:26:59,321 - INFO - WorkerThread-1 - transcribed seq=48 len=236
2025-08-24 02:26:59,321 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:59,322 - INFO - WorkerThread-1 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 02:26:59,460 - INFO - WorkerThread-0 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 02:26:59,462 - INFO - WorkerThread-0 - transcribed seq=49 len=185
2025-08-24 02:26:59,467 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:26:59,468 - INFO - WorkerThread-0 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 02:27:00,677 - INFO - WorkerThread-1 - 转写完成: 050.wav, 文本长度: 185
2025-08-24 02:27:00,678 - INFO - WorkerThread-1 - transcribed seq=50 len=185
2025-08-24 02:27:00,679 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:27:00,679 - INFO - WorkerThread-1 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 02:27:00,796 - INFO - WorkerThread-0 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 02:27:00,796 - INFO - WorkerThread-0 - transcribed seq=51 len=163
2025-08-24 02:27:00,798 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:27:00,799 - INFO - WorkerThread-0 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 02:27:01,990 - INFO - WorkerThread-0 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 02:27:01,991 - INFO - WorkerThread-0 - transcribed seq=53 len=176
2025-08-24 02:27:01,991 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:27:01,991 - INFO - WorkerThread-0 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 02:27:02,139 - INFO - WorkerThread-1 - 转写完成: 052.wav, 文本长度: 167
2025-08-24 02:27:02,140 - INFO - WorkerThread-1 - transcribed seq=52 len=167
2025-08-24 02:27:02,682 - INFO - WorkerThread-0 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 02:27:02,683 - INFO - WorkerThread-0 - transcribed seq=54 len=121
2025-08-24 02:27:14,309 - INFO - MergeThread - 合并完成: archive\full_042_to_054.txt
2025-08-24 02:27:16,820 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.810511 seconds
2025-08-24 02:27:18,014 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:27:38,016 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:27:38,047 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:27:38,533 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:27:58,544 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.447429 seconds
2025-08-24 02:27:59,463 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:28:19,469 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.935271 seconds
2025-08-24 02:28:20,827 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:28:40,901 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:28:40,909 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:28:41,508 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:29:01,524 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.436091 seconds
2025-08-24 02:29:02,334 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:29:22,347 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.898766 seconds
2025-08-24 02:29:23,711 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:29:43,714 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:29:43,723 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:29:43,724 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:29:43,724 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:29:43,725 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:29:43,726 - INFO - PolishProcessor - 润色完成: full_005_to_036.txt -> polished_full_005_to_036.txt (耗时: 187.98秒)
2025-08-24 02:29:44,743 - INFO - PolishProcessor - 开始处理文件: full_037_to_054.txt
2025-08-24 02:29:44,750 - INFO - PolishProcessor - 检测到长文本 (3298 字符)，启用分段处理
2025-08-24 02:29:44,750 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:29:44,751 - INFO - PolishProcessor - 处理第 1 个分段 (3299 字符, 1/1 句子)
2025-08-24 02:29:45,061 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:30:05,068 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.402025 seconds
2025-08-24 02:30:05,853 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:30:25,865 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.924172 seconds
2025-08-24 02:30:27,166 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:30:47,175 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:30:47,182 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:30:47,555 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:31:07,569 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.440425 seconds
2025-08-24 02:31:08,282 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:31:28,299 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.854154 seconds
2025-08-24 02:31:29,616 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:31:49,619 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:31:49,628 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:31:49,937 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:32:09,944 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.386486 seconds
2025-08-24 02:32:10,644 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:32:30,656 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.873828 seconds
2025-08-24 02:32:31,872 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:32:51,885 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:32:51,891 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:32:51,892 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:32:51,893 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:32:51,893 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:32:51,894 - INFO - PolishProcessor - 润色完成: full_037_to_054.txt -> polished_full_037_to_054.txt (耗时: 187.14秒)
2025-08-24 02:32:52,903 - INFO - PolishProcessor - 发现 3 个待处理文件
2025-08-24 02:32:52,904 - INFO - PolishProcessor - 开始处理文件: full_000_to_010.txt
2025-08-24 02:32:52,905 - INFO - PolishProcessor - 检测到长文本 (1577 字符)，启用分段处理
2025-08-24 02:32:52,906 - INFO - PolishProcessor - 长文本检测，使用中等分段 (400 字符)
2025-08-24 02:32:52,907 - INFO - PolishProcessor - 处理第 1 个分段 (1578 字符, 1/1 句子)
2025-08-24 02:32:53,200 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:33:13,216 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.464770 seconds
2025-08-24 02:33:14,022 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:33:34,030 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.811049 seconds
2025-08-24 02:33:35,175 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:33:55,187 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:33:55,221 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:33:55,516 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:34:15,521 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.422704 seconds
2025-08-24 02:34:16,258 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:34:36,263 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.937373 seconds
2025-08-24 02:34:37,514 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:34:57,523 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:34:57,523 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:34:57,770 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:35:17,775 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.386282 seconds
2025-08-24 02:35:18,424 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:35:38,440 - INFO - PolishProcessor - Retrying request to /chat/completions in 0.754304 seconds
2025-08-24 02:35:39,453 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:35:59,455 - ERROR - PolishProcessor - 润色处理异常: Request timed out.
Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 127, in __iter__
    for part in self._httpcore_stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 407, in __iter__
    raise exc from None
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\connection_pool.py", line 403, in __iter__
    for part in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 342, in __iter__
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 334, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 203, in _receive_response_body
    event = self._receive_event(timeout=timeout)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_sync\http11.py", line 217, in _receive_event
    data = self._network_stream.read(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_backends\sync.py", line 128, in read
    return self._sock.recv(max_bytes)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 928, in send
    raise exc
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 922, in send
    response.read()
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 881, in read
    self._content = b"".join(self.iter_bytes())
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 897, in iter_bytes
    for raw_bytes in self.iter_raw():
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_models.py", line 951, in iter_raw
    for raw_stream_bytes in self.stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_client.py", line 153, in __iter__
    for chunk in self._stream:
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 128, in __iter__
    yield part
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\contextlib.py", line 137, in __exit__
    self.gen.throw(typ, value, traceback)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: The read operation timed out

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1000, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.
2025-08-24 02:35:59,459 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:35:59,459 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:35:59,460 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:35:59,460 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:35:59,471 - INFO - PolishProcessor - 润色完成: full_000_to_010.txt -> polished_full_000_to_010.txt (耗时: 186.55秒)
2025-08-24 02:36:00,474 - INFO - PolishProcessor - 开始处理文件: full_011_to_041.txt
2025-08-24 02:36:00,475 - INFO - PolishProcessor - 检测到长文本 (5857 字符)，启用分段处理
2025-08-24 02:36:00,477 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:36:00,477 - INFO - PolishProcessor - 处理第 1 个分段 (5858 字符, 1/1 句子)
2025-08-24 02:36:01,160 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:36:01,180 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:36:01,181 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:36:01,618 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:36:01,620 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:36:01,622 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:36:02,125 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:36:02,127 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:36:02,128 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:36:02,129 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:36:02,129 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:36:02,129 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:36:02,130 - INFO - PolishProcessor - 润色完成: full_011_to_041.txt -> polished_full_011_to_041.txt (耗时: 1.65秒)
2025-08-24 02:36:03,140 - INFO - PolishProcessor - 开始处理文件: full_042_to_054.txt
2025-08-24 02:36:03,143 - INFO - PolishProcessor - 检测到长文本 (2441 字符)，启用分段处理
2025-08-24 02:36:03,144 - INFO - PolishProcessor - 长文本检测，使用中等分段 (400 字符)
2025-08-24 02:36:03,145 - INFO - PolishProcessor - 处理第 1 个分段 (2442 字符, 1/1 句子)
2025-08-24 02:36:03,593 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:36:03,595 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:36:03,596 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:36:04,073 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:36:04,074 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:36:04,076 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:36:04,688 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:36:04,689 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:36:04,691 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:36:04,691 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:36:04,691 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:36:04,691 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:36:04,693 - INFO - PolishProcessor - 润色完成: full_042_to_054.txt -> polished_full_042_to_054.txt (耗时: 1.55秒)
2025-08-24 02:38:06,600 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 02:38:06,601 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 02:38:42,852 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 02:38:44,724 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 02:38:44,736 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 02:38:44,736 - INFO - MainThread - 启动语音转写系统...
2025-08-24 02:38:44,736 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:38:44,736 - INFO - MainThread - SystemManager started
2025-08-24 02:38:44,736 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:38:44,747 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 02:38:44,736 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 02:38:44,747 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 02:38:44,757 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 02:38:44,757 - INFO - MainThread - 润色处理器已启动
2025-08-24 02:38:44,757 - INFO - PolishProcessor - 发现 8 个待处理文件
2025-08-24 02:38:44,757 - INFO - PolishProcessor - 开始处理文件: full_000_to_003.txt
2025-08-24 02:38:47,753 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:47,755 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:47,759 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:38:48,726 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:48,728 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:48,732 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:38:49,495 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 02:38:49,729 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:49,729 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:49,732 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:38:49,732 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:38:49,732 - INFO - PolishProcessor - 润色无变化或失败: full_000_to_003.txt
2025-08-24 02:38:50,734 - INFO - PolishProcessor - 开始处理文件: full_000_to_010.txt
2025-08-24 02:38:50,741 - INFO - PolishProcessor - 检测到长文本 (1577 字符)，启用分段处理
2025-08-24 02:38:50,741 - INFO - PolishProcessor - 长文本检测，使用中等分段 (400 字符)
2025-08-24 02:38:50,742 - INFO - PolishProcessor - 处理第 1 个分段 (1578 字符, 1/1 句子)
2025-08-24 02:38:51,261 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:38:51,265 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:38:51,719 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:51,720 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:51,743 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:38:51,995 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 02:38:51,995 - INFO - WorkerThread-0 - excludes: None
2025-08-24 02:38:52,352 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:38:52,722 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:52,723 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:52,724 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:38:53,659 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:38:53,660 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 02:38:53,745 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:53,745 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:53,746 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:38:53,746 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:38:53,746 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:38:53,747 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:38:53,747 - INFO - PolishProcessor - 润色完成: full_000_to_010.txt -> polished_full_000_to_010.txt (耗时: 3.01秒)
2025-08-24 02:38:54,082 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 02:38:54,750 - INFO - PolishProcessor - 开始处理文件: full_000_to_032.txt
2025-08-24 02:38:54,762 - INFO - PolishProcessor - 检测到长文本 (5886 字符)，启用分段处理
2025-08-24 02:38:54,763 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:38:54,763 - INFO - PolishProcessor - 处理第 1 个分段 (5887 字符, 1/1 句子)
2025-08-24 02:38:55,457 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:38:55,461 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:38:55,914 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:55,919 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:55,933 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:38:56,145 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 02:38:56,146 - INFO - WorkerThread-1 - excludes: None
2025-08-24 02:38:56,550 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:38:57,121 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:57,122 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:57,123 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:38:58,350 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:38:58,351 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:38:58,352 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:38:58,352 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:38:58,352 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:38:58,352 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:38:58,393 - INFO - PolishProcessor - 润色完成: full_000_to_032.txt -> polished_full_000_to_032.txt (耗时: 3.59秒)
2025-08-24 02:38:59,401 - INFO - PolishProcessor - 开始处理文件: full_005_to_036.txt
2025-08-24 02:38:59,403 - INFO - PolishProcessor - 检测到长文本 (6263 字符)，启用分段处理
2025-08-24 02:38:59,404 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:38:59,404 - INFO - PolishProcessor - 处理第 1 个分段 (6264 字符, 1/1 句子)
2025-08-24 02:38:59,920 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:38:59,921 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 02:39:00,105 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 02:39:00,106 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 02:39:00,106 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:00,122 - INFO - WorkerThread-0 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 02:39:00,615 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:00,616 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:00,616 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:01,259 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 02:39:01,259 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 02:39:01,260 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:01,260 - INFO - WorkerThread-1 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 02:39:01,367 - INFO - WorkerThread-0 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 02:39:01,368 - INFO - WorkerThread-0 - transcribed seq=2 len=66
2025-08-24 02:39:01,369 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:01,369 - INFO - WorkerThread-0 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 02:39:01,748 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:01,748 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:01,750 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:02,102 - INFO - MergeThread - 合并完成: archive\full_000_to_002.txt
2025-08-24 02:39:02,540 - INFO - WorkerThread-1 - 转写完成: 003.wav, 文本长度: 78
2025-08-24 02:39:02,540 - INFO - WorkerThread-1 - transcribed seq=3 len=78
2025-08-24 02:39:02,541 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:02,541 - INFO - WorkerThread-1 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 02:39:02,649 - INFO - WorkerThread-0 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 02:39:02,654 - WARNING - WorkerThread-0 - empty transcript, moved to failed handled in job
2025-08-24 02:39:02,655 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:02,655 - INFO - WorkerThread-0 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 02:39:02,810 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:02,810 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:02,812 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:02,812 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:02,813 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:39:02,813 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:39:02,814 - INFO - PolishProcessor - 润色完成: full_005_to_036.txt -> polished_full_005_to_036.txt (耗时: 3.41秒)
2025-08-24 02:39:03,818 - INFO - PolishProcessor - 开始处理文件: full_011_to_041.txt
2025-08-24 02:39:03,826 - INFO - PolishProcessor - 检测到长文本 (5857 字符)，启用分段处理
2025-08-24 02:39:03,826 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:39:03,826 - INFO - PolishProcessor - 处理第 1 个分段 (5858 字符, 1/1 句子)
2025-08-24 02:39:04,024 - INFO - WorkerThread-1 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 02:39:04,024 - INFO - WorkerThread-1 - transcribed seq=5 len=130
2025-08-24 02:39:04,024 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:04,024 - INFO - WorkerThread-1 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 02:39:04,181 - INFO - WorkerThread-0 - 转写完成: 006.wav, 文本长度: 245
2025-08-24 02:39:04,181 - INFO - WorkerThread-0 - transcribed seq=6 len=245
2025-08-24 02:39:04,181 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:04,181 - INFO - WorkerThread-0 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 02:39:05,010 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:05,010 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:05,013 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:05,615 - INFO - WorkerThread-1 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 02:39:05,623 - INFO - WorkerThread-1 - transcribed seq=7 len=234
2025-08-24 02:39:05,623 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:05,623 - INFO - WorkerThread-1 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 02:39:05,779 - INFO - WorkerThread-0 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 02:39:05,788 - INFO - WorkerThread-0 - transcribed seq=8 len=195
2025-08-24 02:39:05,788 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:05,788 - INFO - WorkerThread-0 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 02:39:06,117 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:06,118 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:06,118 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:07,135 - INFO - WorkerThread-1 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 02:39:07,135 - INFO - WorkerThread-1 - transcribed seq=9 len=222
2025-08-24 02:39:07,135 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:07,135 - INFO - WorkerThread-1 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 02:39:07,322 - INFO - WorkerThread-0 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 02:39:07,322 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:07,322 - INFO - WorkerThread-0 - transcribed seq=10 len=230
2025-08-24 02:39:07,322 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:07,332 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:07,333 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:07,333 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:07,334 - INFO - WorkerThread-0 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 02:39:07,334 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:39:07,339 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:39:07,339 - INFO - PolishProcessor - 润色完成: full_011_to_041.txt -> polished_full_011_to_041.txt (耗时: 3.51秒)
2025-08-24 02:39:08,351 - INFO - PolishProcessor - 开始处理文件: full_033_to_054.txt
2025-08-24 02:39:08,351 - INFO - PolishProcessor - 检测到长文本 (3983 字符)，启用分段处理
2025-08-24 02:39:08,351 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:39:08,351 - INFO - PolishProcessor - 处理第 1 个分段 (3984 字符, 1/1 句子)
2025-08-24 02:39:08,564 - INFO - WorkerThread-1 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 02:39:08,571 - INFO - WorkerThread-1 - transcribed seq=11 len=225
2025-08-24 02:39:08,573 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:08,573 - INFO - WorkerThread-1 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 02:39:08,781 - INFO - WorkerThread-0 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 02:39:08,781 - INFO - WorkerThread-0 - transcribed seq=12 len=111
2025-08-24 02:39:08,781 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:08,789 - INFO - WorkerThread-0 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 02:39:09,359 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:09,360 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:09,363 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:10,126 - INFO - WorkerThread-1 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 02:39:10,134 - INFO - WorkerThread-1 - transcribed seq=13 len=212
2025-08-24 02:39:10,134 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:10,134 - INFO - WorkerThread-1 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 02:39:10,339 - INFO - WorkerThread-0 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 02:39:10,339 - INFO - WorkerThread-0 - transcribed seq=14 len=190
2025-08-24 02:39:10,339 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:10,339 - INFO - WorkerThread-0 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 02:39:10,433 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:10,435 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:10,438 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:11,474 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:11,474 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:11,478 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:11,478 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:11,479 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:39:11,479 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:39:11,479 - INFO - PolishProcessor - 润色完成: full_033_to_054.txt -> polished_full_033_to_054.txt (耗时: 3.13秒)
2025-08-24 02:39:11,639 - INFO - WorkerThread-1 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 02:39:11,640 - INFO - WorkerThread-1 - transcribed seq=15 len=162
2025-08-24 02:39:11,640 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:11,640 - INFO - WorkerThread-1 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 02:39:11,825 - INFO - WorkerThread-0 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 02:39:11,825 - INFO - WorkerThread-0 - transcribed seq=16 len=134
2025-08-24 02:39:11,825 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:11,825 - INFO - WorkerThread-0 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 02:39:12,492 - INFO - PolishProcessor - 开始处理文件: full_037_to_054.txt
2025-08-24 02:39:12,502 - INFO - PolishProcessor - 检测到长文本 (3298 字符)，启用分段处理
2025-08-24 02:39:12,502 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:39:12,502 - INFO - PolishProcessor - 处理第 1 个分段 (3299 字符, 1/1 句子)
2025-08-24 02:39:13,133 - INFO - WorkerThread-1 - 转写完成: 017.wav, 文本长度: 169
2025-08-24 02:39:13,133 - INFO - WorkerThread-1 - transcribed seq=17 len=169
2025-08-24 02:39:13,133 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:13,141 - INFO - WorkerThread-1 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 02:39:13,356 - INFO - WorkerThread-0 - 转写完成: 018.wav, 文本长度: 244
2025-08-24 02:39:13,356 - INFO - WorkerThread-0 - transcribed seq=18 len=244
2025-08-24 02:39:13,356 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:13,356 - INFO - WorkerThread-0 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 02:39:13,486 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:13,487 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:13,487 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:14,530 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:14,531 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:14,531 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:14,737 - INFO - WorkerThread-0 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 02:39:14,737 - INFO - WorkerThread-0 - transcribed seq=20 len=214
2025-08-24 02:39:14,739 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:14,739 - INFO - WorkerThread-0 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 02:39:14,894 - INFO - WorkerThread-1 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 02:39:14,894 - INFO - WorkerThread-1 - transcribed seq=19 len=215
2025-08-24 02:39:14,894 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:14,894 - INFO - WorkerThread-1 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 02:39:15,511 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:15,513 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:15,516 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:15,517 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:15,519 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:39:15,520 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:39:15,522 - INFO - PolishProcessor - 润色完成: full_037_to_054.txt -> polished_full_037_to_054.txt (耗时: 3.02秒)
2025-08-24 02:39:16,303 - INFO - WorkerThread-0 - 转写完成: 021.wav, 文本长度: 218
2025-08-24 02:39:16,303 - INFO - WorkerThread-0 - transcribed seq=21 len=218
2025-08-24 02:39:16,309 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:16,309 - INFO - WorkerThread-0 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 02:39:16,483 - INFO - WorkerThread-1 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 02:39:16,483 - INFO - WorkerThread-1 - transcribed seq=22 len=183
2025-08-24 02:39:16,487 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:16,487 - INFO - WorkerThread-1 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 02:39:16,532 - INFO - PolishProcessor - 开始处理文件: full_042_to_054.txt
2025-08-24 02:39:16,533 - INFO - PolishProcessor - 检测到长文本 (2441 字符)，启用分段处理
2025-08-24 02:39:16,535 - INFO - PolishProcessor - 长文本检测，使用中等分段 (400 字符)
2025-08-24 02:39:16,537 - INFO - PolishProcessor - 处理第 1 个分段 (2442 字符, 1/1 句子)
2025-08-24 02:39:17,498 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:17,498 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:17,502 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:17,917 - INFO - WorkerThread-0 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 02:39:17,925 - INFO - WorkerThread-0 - transcribed seq=23 len=223
2025-08-24 02:39:17,925 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:17,925 - INFO - WorkerThread-0 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 02:39:18,150 - INFO - WorkerThread-1 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 02:39:18,153 - INFO - WorkerThread-1 - transcribed seq=24 len=229
2025-08-24 02:39:18,154 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:18,154 - INFO - WorkerThread-1 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 02:39:18,450 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:18,450 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:18,454 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:19,464 - INFO - WorkerThread-0 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 02:39:19,464 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:19,464 - INFO - WorkerThread-0 - transcribed seq=25 len=198
2025-08-24 02:39:19,464 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:19,473 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:19,464 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:19,473 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:19,473 - INFO - WorkerThread-0 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 02:39:19,473 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:39:19,480 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:39:19,486 - INFO - PolishProcessor - 润色完成: full_042_to_054.txt -> polished_full_042_to_054.txt (耗时: 2.95秒)
2025-08-24 02:39:19,690 - INFO - WorkerThread-1 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 02:39:19,690 - INFO - WorkerThread-1 - transcribed seq=26 len=184
2025-08-24 02:39:19,697 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:19,698 - INFO - WorkerThread-1 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 02:39:20,493 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:39:20,501 - INFO - PolishProcessor - 开始处理文件: full_000_to_002.txt
2025-08-24 02:39:21,041 - INFO - WorkerThread-0 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 02:39:21,041 - INFO - WorkerThread-0 - transcribed seq=27 len=195
2025-08-24 02:39:21,049 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:21,049 - INFO - WorkerThread-0 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 02:39:21,273 - INFO - WorkerThread-1 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 02:39:21,282 - INFO - WorkerThread-1 - transcribed seq=28 len=222
2025-08-24 02:39:21,283 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:21,283 - INFO - WorkerThread-1 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 02:39:21,429 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:21,431 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:21,431 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:22,109 - INFO - MergeThread - 合并完成: archive\full_003_to_028.txt
2025-08-24 02:39:22,429 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:22,429 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:22,434 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:22,666 - INFO - WorkerThread-0 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 02:39:22,668 - INFO - WorkerThread-0 - transcribed seq=29 len=164
2025-08-24 02:39:22,668 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:22,673 - INFO - WorkerThread-0 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 02:39:22,903 - INFO - WorkerThread-1 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 02:39:22,903 - INFO - WorkerThread-1 - transcribed seq=30 len=180
2025-08-24 02:39:22,906 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:22,906 - INFO - WorkerThread-1 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 02:39:23,359 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:23,359 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:23,363 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:23,363 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:23,363 - INFO - PolishProcessor - 润色无变化或失败: full_000_to_002.txt
2025-08-24 02:39:24,246 - INFO - WorkerThread-0 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 02:39:24,250 - INFO - WorkerThread-0 - transcribed seq=31 len=206
2025-08-24 02:39:24,250 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:24,251 - INFO - WorkerThread-0 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 02:39:24,485 - INFO - WorkerThread-1 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 02:39:24,485 - INFO - WorkerThread-1 - transcribed seq=32 len=211
2025-08-24 02:39:24,490 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:39:24,491 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:24,491 - INFO - PolishProcessor - 开始处理文件: full_003_to_028.txt
2025-08-24 02:39:24,491 - INFO - WorkerThread-1 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 02:39:24,517 - INFO - PolishProcessor - 检测到长文本 (4886 字符)，启用分段处理
2025-08-24 02:39:24,517 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:39:24,524 - INFO - PolishProcessor - 处理第 1 个分段 (4887 字符, 1/1 句子)
2025-08-24 02:39:25,587 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:25,589 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:25,589 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:25,869 - INFO - WorkerThread-0 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 02:39:25,869 - INFO - WorkerThread-0 - transcribed seq=33 len=222
2025-08-24 02:39:25,869 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:25,869 - INFO - WorkerThread-0 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 02:39:26,107 - INFO - WorkerThread-1 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 02:39:26,107 - INFO - WorkerThread-1 - transcribed seq=34 len=130
2025-08-24 02:39:26,107 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:26,107 - INFO - WorkerThread-1 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 02:39:26,715 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:26,715 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:26,718 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:27,418 - INFO - WorkerThread-0 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 02:39:27,418 - INFO - WorkerThread-0 - transcribed seq=35 len=203
2025-08-24 02:39:27,418 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:27,418 - INFO - WorkerThread-0 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 02:39:27,681 - INFO - WorkerThread-1 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 02:39:27,681 - INFO - WorkerThread-1 - transcribed seq=36 len=127
2025-08-24 02:39:27,684 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:27,684 - INFO - WorkerThread-1 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 02:39:27,786 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:27,786 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:27,788 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:27,788 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:27,788 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:39:27,788 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:39:27,793 - INFO - PolishProcessor - 润色完成: full_003_to_028.txt -> polished_full_003_to_028.txt (耗时: 3.27秒)
2025-08-24 02:39:29,019 - INFO - WorkerThread-0 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 02:39:29,019 - INFO - WorkerThread-0 - transcribed seq=37 len=78
2025-08-24 02:39:29,019 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:29,019 - INFO - WorkerThread-0 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 02:39:29,210 - INFO - WorkerThread-1 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 02:39:29,218 - INFO - WorkerThread-1 - transcribed seq=38 len=149
2025-08-24 02:39:29,218 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:29,218 - INFO - WorkerThread-1 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 02:39:30,617 - INFO - WorkerThread-0 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 02:39:30,623 - INFO - WorkerThread-0 - transcribed seq=39 len=199
2025-08-24 02:39:30,624 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:30,624 - INFO - WorkerThread-0 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 02:39:30,843 - INFO - WorkerThread-1 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 02:39:30,843 - INFO - WorkerThread-1 - transcribed seq=40 len=194
2025-08-24 02:39:30,843 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:30,852 - INFO - WorkerThread-1 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 02:39:32,211 - INFO - WorkerThread-0 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 02:39:32,211 - INFO - WorkerThread-0 - transcribed seq=41 len=232
2025-08-24 02:39:32,211 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:32,211 - INFO - WorkerThread-0 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 02:39:32,383 - INFO - WorkerThread-1 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 02:39:32,383 - INFO - WorkerThread-1 - transcribed seq=42 len=203
2025-08-24 02:39:32,391 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:32,391 - INFO - WorkerThread-1 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 02:39:33,818 - INFO - WorkerThread-0 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 02:39:33,821 - INFO - WorkerThread-0 - transcribed seq=43 len=202
2025-08-24 02:39:33,821 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:33,824 - INFO - WorkerThread-0 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 02:39:33,984 - INFO - WorkerThread-1 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 02:39:33,985 - INFO - WorkerThread-1 - transcribed seq=44 len=199
2025-08-24 02:39:33,985 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:33,988 - INFO - WorkerThread-1 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 02:39:35,450 - INFO - WorkerThread-0 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 02:39:35,450 - INFO - WorkerThread-0 - transcribed seq=45 len=207
2025-08-24 02:39:35,450 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:35,450 - INFO - WorkerThread-0 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 02:39:35,614 - INFO - WorkerThread-1 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 02:39:35,614 - INFO - WorkerThread-1 - transcribed seq=46 len=212
2025-08-24 02:39:35,616 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:35,616 - INFO - WorkerThread-1 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 02:39:37,008 - INFO - WorkerThread-1 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 02:39:37,008 - INFO - WorkerThread-1 - transcribed seq=48 len=236
2025-08-24 02:39:37,008 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:37,014 - INFO - WorkerThread-1 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 02:39:37,160 - INFO - WorkerThread-0 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 02:39:37,160 - INFO - WorkerThread-0 - transcribed seq=47 len=173
2025-08-24 02:39:37,160 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:37,160 - INFO - WorkerThread-0 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 02:39:38,654 - INFO - WorkerThread-1 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 02:39:38,654 - INFO - WorkerThread-1 - transcribed seq=49 len=185
2025-08-24 02:39:38,654 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:38,654 - INFO - WorkerThread-1 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 02:39:38,831 - INFO - WorkerThread-0 - 转写完成: 050.wav, 文本长度: 186
2025-08-24 02:39:38,834 - INFO - WorkerThread-0 - transcribed seq=50 len=186
2025-08-24 02:39:38,834 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:38,834 - INFO - WorkerThread-0 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 02:39:40,259 - INFO - WorkerThread-1 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 02:39:40,259 - INFO - WorkerThread-1 - transcribed seq=51 len=163
2025-08-24 02:39:40,264 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:40,265 - INFO - WorkerThread-1 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 02:39:40,486 - INFO - WorkerThread-0 - 转写完成: 052.wav, 文本长度: 166
2025-08-24 02:39:40,494 - INFO - WorkerThread-0 - transcribed seq=52 len=166
2025-08-24 02:39:40,495 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:39:40,496 - INFO - WorkerThread-0 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 02:39:41,768 - INFO - WorkerThread-1 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 02:39:41,768 - INFO - WorkerThread-1 - transcribed seq=53 len=176
2025-08-24 02:39:41,941 - INFO - WorkerThread-0 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 02:39:41,949 - INFO - WorkerThread-0 - transcribed seq=54 len=121
2025-08-24 02:39:42,114 - INFO - MergeThread - 合并完成: archive\full_029_to_054.txt
2025-08-24 02:39:43,070 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:39:43,071 - INFO - PolishProcessor - 开始处理文件: full_029_to_054.txt
2025-08-24 02:39:43,092 - INFO - PolishProcessor - 检测到长文本 (4749 字符)，启用分段处理
2025-08-24 02:39:43,101 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:39:43,101 - INFO - PolishProcessor - 处理第 1 个分段 (4750 字符, 1/1 句子)
2025-08-24 02:39:45,295 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:45,297 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:45,299 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 1/3
2025-08-24 02:39:46,316 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:46,318 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:46,319 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 2/3
2025-08-24 02:39:47,463 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 402 Payment Required"
2025-08-24 02:39:47,463 - ERROR - PolishProcessor - 润色处理异常: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
Traceback (most recent call last):
  File "D:\codingFiles\pythonFiles\AllPythonCodingFiles\forGPU\LLM_detect10\src\polish_service.py", line 79, in polish_text
    response = self.client.chat.completions.create(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_utils\_utils.py", line 287, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\resources\chat\completions\completions.py", line 1147, in create
    return self._post(
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
  File "C:\Users\21079\.conda\envs\pytorchGPUcp39\lib\site-packages\openai\_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
openai.APIStatusError: Error code: 402 - {'error': {'message': 'Insufficient Balance', 'type': 'unknown_error', 'param': None, 'code': 'invalid_request_error'}}
2025-08-24 02:39:47,463 - WARNING - PolishProcessor - 润色返回空结果，尝试重试 3/3
2025-08-24 02:39:47,467 - WARNING - PolishProcessor - 润色失败，返回原文本
2025-08-24 02:39:47,468 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:39:47,468 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:39:47,470 - INFO - PolishProcessor - 润色完成: full_029_to_054.txt -> polished_full_029_to_054.txt (耗时: 4.38秒)
2025-08-24 02:40:18,692 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 02:40:18,692 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 02:40:45,222 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 02:40:46,102 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 02:40:46,102 - INFO - MainThread - 加载已处理文件列表: 11 个文件
2025-08-24 02:40:46,102 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 02:40:46,104 - INFO - MainThread - 启动语音转写系统...
2025-08-24 02:40:46,105 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:40:46,106 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 02:40:46,106 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:40:46,107 - INFO - MainThread - SystemManager started
2025-08-24 02:40:46,108 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 02:40:46,108 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 02:40:46,109 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 02:40:46,110 - INFO - MainThread - 润色处理器已启动
2025-08-24 02:40:50,097 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 02:40:51,691 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:40:51,696 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:40:52,313 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 02:40:52,313 - INFO - WorkerThread-1 - excludes: None
2025-08-24 02:40:52,692 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:40:53,961 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:40:53,961 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 02:40:55,132 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 02:40:56,521 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:40:56,527 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:40:57,200 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 02:40:57,201 - INFO - WorkerThread-0 - excludes: None
2025-08-24 02:40:57,526 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:41:00,160 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:00,161 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 02:41:00,318 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 02:41:00,319 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 02:41:00,319 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:00,334 - INFO - WorkerThread-1 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 02:41:01,333 - INFO - WorkerThread-1 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 02:41:01,334 - INFO - WorkerThread-1 - transcribed seq=2 len=66
2025-08-24 02:41:01,335 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:01,335 - INFO - WorkerThread-1 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 02:41:01,429 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 02:41:01,431 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 02:41:01,431 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:01,431 - INFO - WorkerThread-0 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 02:41:02,500 - INFO - WorkerThread-1 - 转写完成: 003.wav, 文本长度: 78
2025-08-24 02:41:02,500 - INFO - WorkerThread-1 - transcribed seq=3 len=78
2025-08-24 02:41:02,500 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:02,501 - INFO - WorkerThread-1 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 02:41:02,608 - INFO - WorkerThread-0 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 02:41:02,608 - WARNING - WorkerThread-0 - empty transcript, moved to failed handled in job
2025-08-24 02:41:02,609 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:02,609 - INFO - WorkerThread-0 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 02:41:03,724 - INFO - WorkerThread-0 - 转写完成: 006.wav, 文本长度: 245
2025-08-24 02:41:03,725 - INFO - WorkerThread-0 - transcribed seq=6 len=245
2025-08-24 02:41:03,726 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:03,726 - INFO - WorkerThread-0 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 02:41:03,815 - INFO - WorkerThread-1 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 02:41:03,816 - INFO - WorkerThread-1 - transcribed seq=5 len=130
2025-08-24 02:41:03,816 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:03,817 - INFO - WorkerThread-1 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 02:41:04,467 - INFO - MergeThread - 合并完成: archive\full_000_to_006.txt
2025-08-24 02:41:04,512 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:41:04,513 - INFO - PolishProcessor - 开始处理文件: full_000_to_006.txt
2025-08-24 02:41:05,065 - INFO - WorkerThread-0 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 02:41:05,067 - INFO - WorkerThread-0 - transcribed seq=7 len=234
2025-08-24 02:41:05,068 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:05,069 - INFO - WorkerThread-0 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 02:41:05,167 - INFO - WorkerThread-1 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 02:41:05,167 - INFO - WorkerThread-1 - transcribed seq=8 len=195
2025-08-24 02:41:05,168 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:05,169 - INFO - WorkerThread-1 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 02:41:06,240 - INFO - WorkerThread-1 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 02:41:06,240 - INFO - WorkerThread-1 - transcribed seq=10 len=230
2025-08-24 02:41:06,241 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:06,241 - INFO - WorkerThread-1 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 02:41:06,504 - INFO - WorkerThread-0 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 02:41:06,504 - INFO - WorkerThread-0 - transcribed seq=9 len=222
2025-08-24 02:41:06,505 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:06,505 - INFO - WorkerThread-0 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 02:41:06,967 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:41:07,486 - INFO - WorkerThread-1 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 02:41:07,487 - INFO - WorkerThread-1 - transcribed seq=11 len=225
2025-08-24 02:41:07,487 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:07,488 - INFO - WorkerThread-1 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 02:41:07,600 - INFO - WorkerThread-0 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 02:41:07,601 - INFO - WorkerThread-0 - transcribed seq=12 len=111
2025-08-24 02:41:07,601 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:07,602 - INFO - WorkerThread-0 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 02:41:08,732 - INFO - WorkerThread-0 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 02:41:08,733 - INFO - WorkerThread-0 - transcribed seq=14 len=190
2025-08-24 02:41:08,734 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:08,735 - INFO - WorkerThread-0 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 02:41:08,828 - INFO - WorkerThread-1 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 02:41:08,828 - INFO - WorkerThread-1 - transcribed seq=13 len=212
2025-08-24 02:41:08,829 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:08,829 - INFO - WorkerThread-1 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 02:41:09,978 - INFO - WorkerThread-1 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 02:41:09,979 - INFO - WorkerThread-1 - transcribed seq=16 len=134
2025-08-24 02:41:10,068 - INFO - WorkerThread-0 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 02:41:10,069 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:10,069 - INFO - WorkerThread-0 - transcribed seq=15 len=162
2025-08-24 02:41:10,069 - INFO - WorkerThread-1 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 02:41:10,069 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:10,073 - INFO - WorkerThread-0 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 02:41:11,206 - INFO - WorkerThread-0 - 转写完成: 018.wav, 文本长度: 244
2025-08-24 02:41:11,206 - INFO - WorkerThread-0 - transcribed seq=18 len=244
2025-08-24 02:41:11,207 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:11,207 - INFO - WorkerThread-0 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 02:41:11,322 - INFO - WorkerThread-1 - 转写完成: 017.wav, 文本长度: 169
2025-08-24 02:41:11,322 - INFO - WorkerThread-1 - transcribed seq=17 len=169
2025-08-24 02:41:11,323 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:11,323 - INFO - WorkerThread-1 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 02:41:12,450 - INFO - WorkerThread-0 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 02:41:12,450 - INFO - WorkerThread-0 - transcribed seq=19 len=215
2025-08-24 02:41:12,450 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:12,451 - INFO - WorkerThread-0 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 02:41:12,557 - INFO - WorkerThread-1 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 02:41:12,557 - INFO - WorkerThread-1 - transcribed seq=20 len=214
2025-08-24 02:41:12,558 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:12,558 - INFO - WorkerThread-1 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 02:41:13,698 - INFO - WorkerThread-1 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 02:41:13,698 - INFO - WorkerThread-1 - transcribed seq=22 len=183
2025-08-24 02:41:13,699 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:13,700 - INFO - WorkerThread-1 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 02:41:13,810 - INFO - WorkerThread-0 - 转写完成: 021.wav, 文本长度: 218
2025-08-24 02:41:13,810 - INFO - WorkerThread-0 - transcribed seq=21 len=218
2025-08-24 02:41:13,811 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:13,812 - INFO - WorkerThread-0 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 02:41:14,948 - INFO - WorkerThread-1 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 02:41:14,949 - INFO - WorkerThread-1 - transcribed seq=23 len=223
2025-08-24 02:41:14,951 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:14,952 - INFO - WorkerThread-1 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 02:41:15,050 - INFO - WorkerThread-0 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 02:41:15,050 - INFO - WorkerThread-0 - transcribed seq=24 len=229
2025-08-24 02:41:15,051 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:15,052 - INFO - WorkerThread-0 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 02:41:16,205 - INFO - WorkerThread-0 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 02:41:16,206 - INFO - WorkerThread-0 - transcribed seq=26 len=184
2025-08-24 02:41:16,207 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:16,207 - INFO - WorkerThread-0 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 02:41:16,347 - INFO - WorkerThread-1 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 02:41:16,351 - INFO - WorkerThread-1 - transcribed seq=25 len=198
2025-08-24 02:41:16,355 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:16,356 - INFO - WorkerThread-1 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 02:41:17,419 - INFO - WorkerThread-0 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 02:41:17,420 - INFO - WorkerThread-0 - transcribed seq=27 len=195
2025-08-24 02:41:17,420 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:17,421 - INFO - WorkerThread-0 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 02:41:17,557 - INFO - WorkerThread-1 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 02:41:17,557 - INFO - WorkerThread-1 - transcribed seq=28 len=222
2025-08-24 02:41:17,558 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:17,559 - INFO - WorkerThread-1 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 02:41:18,644 - INFO - WorkerThread-1 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 02:41:18,645 - INFO - WorkerThread-1 - transcribed seq=30 len=180
2025-08-24 02:41:18,645 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:18,646 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 02:41:18,750 - INFO - WorkerThread-0 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 02:41:18,750 - INFO - WorkerThread-0 - transcribed seq=29 len=164
2025-08-24 02:41:18,751 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:18,751 - INFO - WorkerThread-0 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 02:41:19,821 - INFO - WorkerThread-0 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 02:41:19,821 - INFO - WorkerThread-0 - transcribed seq=32 len=211
2025-08-24 02:41:19,822 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:19,822 - INFO - WorkerThread-0 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 02:41:19,964 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 02:41:19,965 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 02:41:19,971 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:19,985 - INFO - WorkerThread-1 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 02:41:21,106 - INFO - WorkerThread-1 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 02:41:21,106 - INFO - WorkerThread-1 - transcribed seq=34 len=130
2025-08-24 02:41:21,107 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:21,107 - INFO - WorkerThread-1 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 02:41:21,217 - INFO - WorkerThread-0 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 02:41:21,220 - INFO - WorkerThread-0 - transcribed seq=33 len=222
2025-08-24 02:41:21,221 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:21,221 - INFO - WorkerThread-0 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 02:41:22,322 - INFO - WorkerThread-1 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 02:41:22,322 - INFO - WorkerThread-1 - transcribed seq=35 len=203
2025-08-24 02:41:22,323 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:22,323 - INFO - WorkerThread-1 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 02:41:22,499 - INFO - WorkerThread-0 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 02:41:22,499 - INFO - WorkerThread-0 - transcribed seq=36 len=127
2025-08-24 02:41:22,500 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:22,501 - INFO - WorkerThread-0 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 02:41:23,553 - INFO - WorkerThread-0 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 02:41:23,554 - INFO - WorkerThread-0 - transcribed seq=38 len=149
2025-08-24 02:41:23,554 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:23,555 - INFO - WorkerThread-0 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 02:41:23,656 - INFO - WorkerThread-1 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 02:41:23,656 - INFO - WorkerThread-1 - transcribed seq=37 len=78
2025-08-24 02:41:23,657 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:23,657 - INFO - WorkerThread-1 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 02:41:24,473 - INFO - MergeThread - 合并完成: archive\full_007_to_038.txt
2025-08-24 02:41:24,811 - INFO - WorkerThread-0 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 02:41:24,812 - INFO - WorkerThread-0 - transcribed seq=39 len=199
2025-08-24 02:41:24,814 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:24,815 - INFO - WorkerThread-0 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 02:41:24,937 - INFO - WorkerThread-1 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 02:41:24,937 - INFO - WorkerThread-1 - transcribed seq=40 len=194
2025-08-24 02:41:24,940 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:24,941 - INFO - WorkerThread-1 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 02:41:26,022 - INFO - WorkerThread-1 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 02:41:26,022 - INFO - WorkerThread-1 - transcribed seq=42 len=203
2025-08-24 02:41:26,023 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:26,023 - INFO - WorkerThread-1 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 02:41:26,196 - INFO - WorkerThread-0 - 转写完成: 041.wav, 文本长度: 231
2025-08-24 02:41:26,197 - INFO - WorkerThread-0 - transcribed seq=41 len=231
2025-08-24 02:41:26,198 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:26,198 - INFO - WorkerThread-0 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 02:41:27,166 - INFO - WorkerThread-1 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 02:41:27,167 - INFO - WorkerThread-1 - transcribed seq=43 len=202
2025-08-24 02:41:27,168 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:27,168 - INFO - WorkerThread-1 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 02:41:27,652 - INFO - WorkerThread-0 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 02:41:27,653 - INFO - WorkerThread-0 - transcribed seq=44 len=199
2025-08-24 02:41:27,654 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:27,654 - INFO - WorkerThread-0 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 02:41:28,322 - INFO - WorkerThread-1 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 02:41:28,323 - INFO - WorkerThread-1 - transcribed seq=45 len=207
2025-08-24 02:41:28,323 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:28,324 - INFO - WorkerThread-1 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 02:41:29,036 - INFO - WorkerThread-0 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 02:41:29,036 - INFO - WorkerThread-0 - transcribed seq=46 len=212
2025-08-24 02:41:29,037 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:29,037 - INFO - WorkerThread-0 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 02:41:29,326 - INFO - WorkerThread-1 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 02:41:29,327 - INFO - WorkerThread-1 - transcribed seq=47 len=173
2025-08-24 02:41:29,327 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:29,328 - INFO - WorkerThread-1 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 02:41:30,364 - INFO - WorkerThread-0 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 02:41:30,365 - INFO - WorkerThread-0 - transcribed seq=48 len=236
2025-08-24 02:41:30,365 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:30,366 - INFO - WorkerThread-0 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 02:41:30,488 - INFO - WorkerThread-1 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 02:41:30,488 - INFO - WorkerThread-1 - transcribed seq=49 len=185
2025-08-24 02:41:30,491 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:30,492 - INFO - WorkerThread-1 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 02:41:31,653 - INFO - WorkerThread-0 - 转写完成: 050.wav, 文本长度: 185
2025-08-24 02:41:31,654 - INFO - WorkerThread-0 - transcribed seq=50 len=185
2025-08-24 02:41:31,654 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:31,655 - INFO - WorkerThread-0 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 02:41:31,761 - INFO - WorkerThread-1 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 02:41:31,761 - INFO - WorkerThread-1 - transcribed seq=51 len=163
2025-08-24 02:41:31,762 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:31,763 - INFO - WorkerThread-1 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 02:41:32,955 - INFO - WorkerThread-0 - 转写完成: 052.wav, 文本长度: 166
2025-08-24 02:41:32,955 - INFO - WorkerThread-0 - transcribed seq=52 len=166
2025-08-24 02:41:32,956 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:41:32,956 - INFO - WorkerThread-0 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 02:41:33,096 - INFO - WorkerThread-1 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 02:41:33,098 - INFO - WorkerThread-1 - transcribed seq=53 len=176
2025-08-24 02:41:33,605 - INFO - WorkerThread-0 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 02:41:33,605 - INFO - WorkerThread-0 - transcribed seq=54 len=121
2025-08-24 02:41:34,236 - INFO - PolishProcessor - 润色成功，文本长度: 688 -> 707
2025-08-24 02:41:34,237 - INFO - PolishProcessor - 润色完成: full_000_to_006.txt -> polished_full_000_to_006.txt (耗时: 29.70秒)
2025-08-24 02:41:35,255 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:41:35,255 - INFO - PolishProcessor - 开始处理文件: full_007_to_038.txt
2025-08-24 02:41:35,279 - INFO - PolishProcessor - 检测到长文本 (6110 字符)，启用分段处理
2025-08-24 02:41:35,280 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:41:35,280 - INFO - PolishProcessor - 处理第 1 个分段 (6111 字符, 1/1 句子)
2025-08-24 02:41:36,150 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:41:44,478 - INFO - MergeThread - 合并完成: archive\full_039_to_054.txt
2025-08-24 02:42:06,152 - INFO - PolishProcessor - 润色成功，文本长度: 6111 -> 833
2025-08-24 02:42:06,152 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:42:06,153 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:42:06,154 - INFO - PolishProcessor - 润色完成: full_007_to_038.txt -> polished_full_007_to_038.txt (耗时: 30.87秒)
2025-08-24 02:42:07,157 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:42:07,158 - INFO - PolishProcessor - 开始处理文件: full_039_to_054.txt
2025-08-24 02:42:07,180 - INFO - PolishProcessor - 检测到长文本 (3067 字符)，启用分段处理
2025-08-24 02:42:07,184 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:42:07,185 - INFO - PolishProcessor - 处理第 1 个分段 (3068 字符, 1/1 句子)
2025-08-24 02:42:07,876 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:42:57,674 - INFO - PolishProcessor - 润色成功，文本长度: 3068 -> 1772
2025-08-24 02:42:57,674 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:42:57,675 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:42:57,676 - INFO - PolishProcessor - 润色完成: full_039_to_054.txt -> polished_full_039_to_054.txt (耗时: 50.49秒)
2025-08-24 02:43:23,852 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 02:43:23,852 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 02:44:46,309 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 02:44:47,146 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 02:44:47,147 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 02:44:47,147 - INFO - MainThread - 启动语音转写系统...
2025-08-24 02:44:47,149 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:44:47,150 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 02:44:47,151 - INFO - MainThread - SystemManager started
2025-08-24 02:44:47,151 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 02:44:47,151 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:44:47,154 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 02:44:47,154 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 02:44:47,154 - INFO - MainThread - 润色处理器已启动
2025-08-24 02:44:51,762 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 02:44:53,390 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:44:53,394 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:44:53,994 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 02:44:53,994 - INFO - WorkerThread-1 - excludes: None
2025-08-24 02:44:54,340 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:44:55,620 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:44:55,622 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 1.83 MB)
2025-08-24 02:44:56,264 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 02:44:57,818 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:44:57,830 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 02:44:59,103 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 02:44:59,103 - INFO - WorkerThread-0 - excludes: None
2025-08-24 02:44:59,630 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 02:45:01,764 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:01,765 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 1.83 MB)
2025-08-24 02:45:01,870 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 90
2025-08-24 02:45:01,870 - INFO - WorkerThread-1 - transcribed seq=1 len=90
2025-08-24 02:45:01,870 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:01,885 - INFO - WorkerThread-1 - 开始转写文件: 002.wav (大小: 1.83 MB)
2025-08-24 02:45:02,885 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 74
2025-08-24 02:45:02,885 - INFO - WorkerThread-0 - transcribed seq=0 len=74
2025-08-24 02:45:02,886 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:02,886 - INFO - WorkerThread-0 - 开始转写文件: 003.wav (大小: 1.83 MB)
2025-08-24 02:45:02,980 - INFO - WorkerThread-1 - 转写完成: 002.wav, 文本长度: 66
2025-08-24 02:45:02,980 - INFO - WorkerThread-1 - transcribed seq=2 len=66
2025-08-24 02:45:02,982 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:02,982 - INFO - WorkerThread-1 - 开始转写文件: 004.wav (大小: 1.83 MB)
2025-08-24 02:45:03,995 - INFO - WorkerThread-1 - 转写完成: 004.wav, 文本长度: 0
2025-08-24 02:45:03,995 - WARNING - WorkerThread-1 - empty transcript, moved to failed handled in job
2025-08-24 02:45:03,996 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:03,996 - INFO - WorkerThread-1 - 开始转写文件: 005.wav (大小: 1.83 MB)
2025-08-24 02:45:04,105 - INFO - WorkerThread-0 - 转写完成: 003.wav, 文本长度: 78
2025-08-24 02:45:04,106 - INFO - WorkerThread-0 - transcribed seq=3 len=78
2025-08-24 02:45:04,106 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:04,106 - INFO - WorkerThread-0 - 开始转写文件: 006.wav (大小: 1.83 MB)
2025-08-24 02:45:05,146 - INFO - WorkerThread-1 - 转写完成: 005.wav, 文本长度: 130
2025-08-24 02:45:05,146 - INFO - WorkerThread-1 - transcribed seq=5 len=130
2025-08-24 02:45:05,148 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:05,148 - INFO - WorkerThread-1 - 开始转写文件: 007.wav (大小: 1.83 MB)
2025-08-24 02:45:05,273 - INFO - WorkerThread-0 - 转写完成: 006.wav, 文本长度: 245
2025-08-24 02:45:05,273 - INFO - WorkerThread-0 - transcribed seq=6 len=245
2025-08-24 02:45:05,274 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:05,274 - INFO - WorkerThread-0 - 开始转写文件: 008.wav (大小: 1.83 MB)
2025-08-24 02:45:05,547 - INFO - MergeThread - 合并完成: archive\full_000_to_006.txt
2025-08-24 02:45:06,258 - INFO - WorkerThread-1 - 转写完成: 007.wav, 文本长度: 234
2025-08-24 02:45:06,258 - INFO - WorkerThread-1 - transcribed seq=7 len=234
2025-08-24 02:45:06,258 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:06,259 - INFO - WorkerThread-1 - 开始转写文件: 009.wav (大小: 1.83 MB)
2025-08-24 02:45:06,380 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 02:45:06,380 - INFO - PolishProcessor - 开始处理文件: full_000_to_006.txt
2025-08-24 02:45:06,494 - INFO - WorkerThread-0 - 转写完成: 008.wav, 文本长度: 195
2025-08-24 02:45:06,495 - INFO - WorkerThread-0 - transcribed seq=8 len=195
2025-08-24 02:45:06,496 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:06,496 - INFO - WorkerThread-0 - 开始转写文件: 010.wav (大小: 1.83 MB)
2025-08-24 02:45:07,577 - INFO - WorkerThread-1 - 转写完成: 009.wav, 文本长度: 222
2025-08-24 02:45:07,578 - INFO - WorkerThread-1 - transcribed seq=9 len=222
2025-08-24 02:45:07,579 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:07,580 - INFO - WorkerThread-1 - 开始转写文件: 011.wav (大小: 1.83 MB)
2025-08-24 02:45:07,674 - INFO - WorkerThread-0 - 转写完成: 010.wav, 文本长度: 230
2025-08-24 02:45:07,674 - INFO - WorkerThread-0 - transcribed seq=10 len=230
2025-08-24 02:45:07,675 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:07,675 - INFO - WorkerThread-0 - 开始转写文件: 012.wav (大小: 1.83 MB)
2025-08-24 02:45:08,326 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:45:08,768 - INFO - WorkerThread-1 - 转写完成: 011.wav, 文本长度: 225
2025-08-24 02:45:08,769 - INFO - WorkerThread-1 - transcribed seq=11 len=225
2025-08-24 02:45:08,770 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:08,771 - INFO - WorkerThread-1 - 开始转写文件: 013.wav (大小: 1.83 MB)
2025-08-24 02:45:08,865 - INFO - WorkerThread-0 - 转写完成: 012.wav, 文本长度: 111
2025-08-24 02:45:08,865 - INFO - WorkerThread-0 - transcribed seq=12 len=111
2025-08-24 02:45:08,866 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:08,866 - INFO - WorkerThread-0 - 开始转写文件: 014.wav (大小: 1.83 MB)
2025-08-24 02:45:09,976 - INFO - WorkerThread-0 - 转写完成: 014.wav, 文本长度: 190
2025-08-24 02:45:09,976 - INFO - WorkerThread-0 - transcribed seq=14 len=190
2025-08-24 02:45:09,977 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:09,977 - INFO - WorkerThread-0 - 开始转写文件: 015.wav (大小: 1.83 MB)
2025-08-24 02:45:10,073 - INFO - WorkerThread-1 - 转写完成: 013.wav, 文本长度: 212
2025-08-24 02:45:10,075 - INFO - WorkerThread-1 - transcribed seq=13 len=212
2025-08-24 02:45:10,077 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:10,077 - INFO - WorkerThread-1 - 开始转写文件: 016.wav (大小: 1.83 MB)
2025-08-24 02:45:11,140 - INFO - WorkerThread-0 - 转写完成: 015.wav, 文本长度: 162
2025-08-24 02:45:11,140 - INFO - WorkerThread-0 - transcribed seq=15 len=162
2025-08-24 02:45:11,141 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:11,141 - INFO - WorkerThread-0 - 开始转写文件: 017.wav (大小: 1.83 MB)
2025-08-24 02:45:11,259 - INFO - WorkerThread-1 - 转写完成: 016.wav, 文本长度: 134
2025-08-24 02:45:11,264 - INFO - WorkerThread-1 - transcribed seq=16 len=134
2025-08-24 02:45:11,264 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:11,281 - INFO - WorkerThread-1 - 开始转写文件: 018.wav (大小: 1.83 MB)
2025-08-24 02:45:12,333 - INFO - WorkerThread-0 - 转写完成: 017.wav, 文本长度: 169
2025-08-24 02:45:12,333 - INFO - WorkerThread-0 - transcribed seq=17 len=169
2025-08-24 02:45:12,334 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:12,335 - INFO - WorkerThread-0 - 开始转写文件: 019.wav (大小: 1.83 MB)
2025-08-24 02:45:12,464 - INFO - WorkerThread-1 - 转写完成: 018.wav, 文本长度: 244
2025-08-24 02:45:12,465 - INFO - WorkerThread-1 - transcribed seq=18 len=244
2025-08-24 02:45:12,465 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:12,466 - INFO - WorkerThread-1 - 开始转写文件: 020.wav (大小: 1.83 MB)
2025-08-24 02:45:13,537 - INFO - WorkerThread-0 - 转写完成: 019.wav, 文本长度: 215
2025-08-24 02:45:13,537 - INFO - WorkerThread-0 - transcribed seq=19 len=215
2025-08-24 02:45:13,538 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:13,539 - INFO - WorkerThread-0 - 开始转写文件: 021.wav (大小: 1.83 MB)
2025-08-24 02:45:13,651 - INFO - WorkerThread-1 - 转写完成: 020.wav, 文本长度: 214
2025-08-24 02:45:13,652 - INFO - WorkerThread-1 - transcribed seq=20 len=214
2025-08-24 02:45:13,652 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:13,652 - INFO - WorkerThread-1 - 开始转写文件: 022.wav (大小: 1.83 MB)
2025-08-24 02:45:14,753 - INFO - WorkerThread-0 - 转写完成: 021.wav, 文本长度: 219
2025-08-24 02:45:14,754 - INFO - WorkerThread-0 - transcribed seq=21 len=219
2025-08-24 02:45:14,755 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:14,755 - INFO - WorkerThread-0 - 开始转写文件: 023.wav (大小: 1.83 MB)
2025-08-24 02:45:14,864 - INFO - WorkerThread-1 - 转写完成: 022.wav, 文本长度: 183
2025-08-24 02:45:14,865 - INFO - WorkerThread-1 - transcribed seq=22 len=183
2025-08-24 02:45:14,866 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:14,867 - INFO - WorkerThread-1 - 开始转写文件: 024.wav (大小: 1.83 MB)
2025-08-24 02:45:15,564 - INFO - MergeThread - 合并完成: archive\full_007_to_022.txt
2025-08-24 02:45:15,878 - INFO - WorkerThread-0 - 转写完成: 023.wav, 文本长度: 223
2025-08-24 02:45:15,879 - INFO - WorkerThread-0 - transcribed seq=23 len=223
2025-08-24 02:45:15,884 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:15,884 - INFO - WorkerThread-0 - 开始转写文件: 025.wav (大小: 1.83 MB)
2025-08-24 02:45:16,070 - INFO - WorkerThread-1 - 转写完成: 024.wav, 文本长度: 229
2025-08-24 02:45:16,072 - INFO - WorkerThread-1 - transcribed seq=24 len=229
2025-08-24 02:45:16,073 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:16,074 - INFO - WorkerThread-1 - 开始转写文件: 026.wav (大小: 1.83 MB)
2025-08-24 02:45:17,155 - INFO - WorkerThread-1 - 转写完成: 026.wav, 文本长度: 184
2025-08-24 02:45:17,156 - INFO - WorkerThread-1 - transcribed seq=26 len=184
2025-08-24 02:45:17,156 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:17,157 - INFO - WorkerThread-1 - 开始转写文件: 027.wav (大小: 1.83 MB)
2025-08-24 02:45:17,253 - INFO - WorkerThread-0 - 转写完成: 025.wav, 文本长度: 198
2025-08-24 02:45:17,255 - INFO - WorkerThread-0 - transcribed seq=25 len=198
2025-08-24 02:45:17,256 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:17,257 - INFO - WorkerThread-0 - 开始转写文件: 028.wav (大小: 1.83 MB)
2025-08-24 02:45:18,305 - INFO - WorkerThread-1 - 转写完成: 027.wav, 文本长度: 195
2025-08-24 02:45:18,306 - INFO - WorkerThread-1 - transcribed seq=27 len=195
2025-08-24 02:45:18,307 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:18,307 - INFO - WorkerThread-1 - 开始转写文件: 029.wav (大小: 1.83 MB)
2025-08-24 02:45:18,419 - INFO - WorkerThread-0 - 转写完成: 028.wav, 文本长度: 222
2025-08-24 02:45:18,419 - INFO - WorkerThread-0 - transcribed seq=28 len=222
2025-08-24 02:45:18,419 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:18,420 - INFO - WorkerThread-0 - 开始转写文件: 030.wav (大小: 1.83 MB)
2025-08-24 02:45:19,456 - INFO - WorkerThread-1 - 转写完成: 029.wav, 文本长度: 164
2025-08-24 02:45:19,456 - INFO - WorkerThread-1 - transcribed seq=29 len=164
2025-08-24 02:45:19,457 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:19,458 - INFO - WorkerThread-1 - 开始转写文件: 031.wav (大小: 1.83 MB)
2025-08-24 02:45:19,573 - INFO - WorkerThread-0 - 转写完成: 030.wav, 文本长度: 180
2025-08-24 02:45:19,573 - INFO - WorkerThread-0 - transcribed seq=30 len=180
2025-08-24 02:45:19,579 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:19,579 - INFO - WorkerThread-0 - 开始转写文件: 032.wav (大小: 1.83 MB)
2025-08-24 02:45:20,642 - INFO - WorkerThread-1 - 转写完成: 031.wav, 文本长度: 206
2025-08-24 02:45:20,642 - INFO - WorkerThread-1 - transcribed seq=31 len=206
2025-08-24 02:45:20,643 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:20,643 - INFO - WorkerThread-1 - 开始转写文件: 033.wav (大小: 1.83 MB)
2025-08-24 02:45:20,761 - INFO - WorkerThread-0 - 转写完成: 032.wav, 文本长度: 211
2025-08-24 02:45:20,761 - INFO - WorkerThread-0 - transcribed seq=32 len=211
2025-08-24 02:45:20,762 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:20,762 - INFO - WorkerThread-0 - 开始转写文件: 034.wav (大小: 1.83 MB)
2025-08-24 02:45:21,832 - INFO - WorkerThread-1 - 转写完成: 033.wav, 文本长度: 222
2025-08-24 02:45:21,832 - INFO - WorkerThread-1 - transcribed seq=33 len=222
2025-08-24 02:45:21,833 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:21,836 - INFO - WorkerThread-1 - 开始转写文件: 035.wav (大小: 1.83 MB)
2025-08-24 02:45:21,955 - INFO - WorkerThread-0 - 转写完成: 034.wav, 文本长度: 130
2025-08-24 02:45:21,955 - INFO - WorkerThread-0 - transcribed seq=34 len=130
2025-08-24 02:45:21,956 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:21,957 - INFO - WorkerThread-0 - 开始转写文件: 036.wav (大小: 1.83 MB)
2025-08-24 02:45:23,000 - INFO - WorkerThread-1 - 转写完成: 035.wav, 文本长度: 203
2025-08-24 02:45:23,001 - INFO - WorkerThread-1 - transcribed seq=35 len=203
2025-08-24 02:45:23,002 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:23,002 - INFO - WorkerThread-1 - 开始转写文件: 037.wav (大小: 1.83 MB)
2025-08-24 02:45:23,118 - INFO - WorkerThread-0 - 转写完成: 036.wav, 文本长度: 127
2025-08-24 02:45:23,119 - INFO - WorkerThread-0 - transcribed seq=36 len=127
2025-08-24 02:45:23,120 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:23,120 - INFO - WorkerThread-0 - 开始转写文件: 038.wav (大小: 1.83 MB)
2025-08-24 02:45:24,171 - INFO - WorkerThread-0 - 转写完成: 038.wav, 文本长度: 149
2025-08-24 02:45:24,172 - INFO - WorkerThread-0 - transcribed seq=38 len=149
2025-08-24 02:45:24,174 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:24,175 - INFO - WorkerThread-0 - 开始转写文件: 039.wav (大小: 1.83 MB)
2025-08-24 02:45:24,274 - INFO - WorkerThread-1 - 转写完成: 037.wav, 文本长度: 78
2025-08-24 02:45:24,276 - INFO - WorkerThread-1 - transcribed seq=37 len=78
2025-08-24 02:45:24,278 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:24,279 - INFO - WorkerThread-1 - 开始转写文件: 040.wav (大小: 1.83 MB)
2025-08-24 02:45:25,223 - INFO - WorkerThread-1 - 转写完成: 040.wav, 文本长度: 194
2025-08-24 02:45:25,223 - INFO - WorkerThread-1 - transcribed seq=40 len=194
2025-08-24 02:45:25,224 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:25,224 - INFO - WorkerThread-1 - 开始转写文件: 041.wav (大小: 1.83 MB)
2025-08-24 02:45:25,579 - INFO - MergeThread - 合并完成: archive\full_023_to_040.txt
2025-08-24 02:45:25,811 - INFO - WorkerThread-0 - 转写完成: 039.wav, 文本长度: 199
2025-08-24 02:45:25,812 - INFO - WorkerThread-0 - transcribed seq=39 len=199
2025-08-24 02:45:25,813 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:25,813 - INFO - WorkerThread-0 - 开始转写文件: 042.wav (大小: 1.83 MB)
2025-08-24 02:45:26,189 - INFO - WorkerThread-1 - 转写完成: 041.wav, 文本长度: 232
2025-08-24 02:45:26,190 - INFO - WorkerThread-1 - transcribed seq=41 len=232
2025-08-24 02:45:26,190 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:26,191 - INFO - WorkerThread-1 - 开始转写文件: 043.wav (大小: 1.83 MB)
2025-08-24 02:45:27,080 - INFO - WorkerThread-0 - 转写完成: 042.wav, 文本长度: 203
2025-08-24 02:45:27,081 - INFO - WorkerThread-0 - transcribed seq=42 len=203
2025-08-24 02:45:27,082 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:27,083 - INFO - WorkerThread-0 - 开始转写文件: 044.wav (大小: 1.83 MB)
2025-08-24 02:45:27,234 - INFO - WorkerThread-1 - 转写完成: 043.wav, 文本长度: 202
2025-08-24 02:45:27,235 - INFO - WorkerThread-1 - transcribed seq=43 len=202
2025-08-24 02:45:27,236 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:27,236 - INFO - WorkerThread-1 - 开始转写文件: 045.wav (大小: 1.83 MB)
2025-08-24 02:45:28,350 - INFO - WorkerThread-1 - 转写完成: 045.wav, 文本长度: 207
2025-08-24 02:45:28,351 - INFO - WorkerThread-1 - transcribed seq=45 len=207
2025-08-24 02:45:28,351 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:28,352 - INFO - WorkerThread-1 - 开始转写文件: 046.wav (大小: 1.83 MB)
2025-08-24 02:45:28,484 - INFO - WorkerThread-0 - 转写完成: 044.wav, 文本长度: 199
2025-08-24 02:45:28,484 - INFO - WorkerThread-0 - transcribed seq=44 len=199
2025-08-24 02:45:28,485 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:28,488 - INFO - WorkerThread-0 - 开始转写文件: 047.wav (大小: 1.83 MB)
2025-08-24 02:45:29,627 - INFO - WorkerThread-1 - 转写完成: 046.wav, 文本长度: 212
2025-08-24 02:45:29,628 - INFO - WorkerThread-1 - transcribed seq=46 len=212
2025-08-24 02:45:29,628 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:29,629 - INFO - WorkerThread-1 - 开始转写文件: 048.wav (大小: 1.83 MB)
2025-08-24 02:45:29,739 - INFO - WorkerThread-0 - 转写完成: 047.wav, 文本长度: 173
2025-08-24 02:45:29,739 - INFO - WorkerThread-0 - transcribed seq=47 len=173
2025-08-24 02:45:29,740 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:29,740 - INFO - WorkerThread-0 - 开始转写文件: 049.wav (大小: 1.83 MB)
2025-08-24 02:45:30,907 - INFO - WorkerThread-1 - 转写完成: 048.wav, 文本长度: 236
2025-08-24 02:45:30,908 - INFO - WorkerThread-1 - transcribed seq=48 len=236
2025-08-24 02:45:30,908 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:30,911 - INFO - WorkerThread-1 - 开始转写文件: 050.wav (大小: 1.83 MB)
2025-08-24 02:45:31,030 - INFO - WorkerThread-0 - 转写完成: 049.wav, 文本长度: 185
2025-08-24 02:45:31,031 - INFO - WorkerThread-0 - transcribed seq=49 len=185
2025-08-24 02:45:31,032 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:31,032 - INFO - WorkerThread-0 - 开始转写文件: 051.wav (大小: 1.83 MB)
2025-08-24 02:45:32,225 - INFO - WorkerThread-0 - 转写完成: 051.wav, 文本长度: 163
2025-08-24 02:45:32,307 - INFO - WorkerThread-1 - 转写完成: 050.wav, 文本长度: 185
2025-08-24 02:45:32,307 - INFO - WorkerThread-0 - transcribed seq=51 len=163
2025-08-24 02:45:32,308 - INFO - WorkerThread-1 - transcribed seq=50 len=185
2025-08-24 02:45:32,308 - INFO - WorkerThread-0 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:32,308 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:32,310 - INFO - WorkerThread-1 - 开始转写文件: 053.wav (大小: 1.83 MB)
2025-08-24 02:45:32,310 - INFO - WorkerThread-0 - 开始转写文件: 052.wav (大小: 1.83 MB)
2025-08-24 02:45:33,486 - INFO - WorkerThread-1 - 转写完成: 053.wav, 文本长度: 176
2025-08-24 02:45:33,486 - INFO - WorkerThread-1 - transcribed seq=53 len=176
2025-08-24 02:45:33,487 - INFO - WorkerThread-1 - 使用缓存的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 02:45:33,488 - INFO - WorkerThread-1 - 开始转写文件: 054.wav (大小: 1.34 MB)
2025-08-24 02:45:33,611 - INFO - WorkerThread-0 - 转写完成: 052.wav, 文本长度: 166
2025-08-24 02:45:33,613 - INFO - WorkerThread-0 - transcribed seq=52 len=166
2025-08-24 02:45:34,099 - INFO - WorkerThread-1 - 转写完成: 054.wav, 文本长度: 121
2025-08-24 02:45:34,100 - INFO - WorkerThread-1 - transcribed seq=54 len=121
2025-08-24 02:45:35,583 - INFO - MergeThread - 合并完成: archive\full_039_to_054.txt
2025-08-24 02:45:36,733 - INFO - PolishProcessor - 润色成功，文本长度: 688 -> 717
2025-08-24 02:45:36,734 - INFO - PolishProcessor - 润色完成: full_000_to_006.txt -> polished_full_000_to_006.txt (耗时: 30.33秒)
2025-08-24 02:45:37,752 - INFO - PolishProcessor - 发现 3 个待处理文件
2025-08-24 02:45:37,755 - INFO - PolishProcessor - 开始处理文件: full_007_to_022.txt
2025-08-24 02:45:37,771 - INFO - PolishProcessor - 检测到长文本 (3174 字符)，启用分段处理
2025-08-24 02:45:37,771 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:45:37,771 - INFO - PolishProcessor - 处理第 1 个分段 (3175 字符, 1/1 句子)
2025-08-24 02:45:38,526 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:46:23,273 - INFO - PolishProcessor - 润色成功，文本长度: 3175 -> 1335
2025-08-24 02:46:23,274 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:46:23,275 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:46:23,276 - INFO - PolishProcessor - 润色完成: full_007_to_022.txt -> polished_full_007_to_022.txt (耗时: 45.50秒)
2025-08-24 02:46:24,292 - INFO - PolishProcessor - 开始处理文件: full_023_to_040.txt
2025-08-24 02:46:24,293 - INFO - PolishProcessor - 检测到长文本 (3131 字符)，启用分段处理
2025-08-24 02:46:24,294 - INFO - PolishProcessor - 超长文本检测，使用小分段 (300 字符)
2025-08-24 02:46:24,304 - INFO - PolishProcessor - 处理第 1 个分段 (3132 字符, 1/1 句子)
2025-08-24 02:46:25,119 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:47:19,593 - INFO - PolishProcessor - 润色成功，文本长度: 3132 -> 1749
2025-08-24 02:47:19,594 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:47:19,595 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:47:19,596 - INFO - PolishProcessor - 润色完成: full_023_to_040.txt -> polished_full_023_to_040.txt (耗时: 55.30秒)
2025-08-24 02:47:20,598 - INFO - PolishProcessor - 开始处理文件: full_039_to_054.txt
2025-08-24 02:47:20,600 - INFO - PolishProcessor - 检测到长文本 (2873 字符)，启用分段处理
2025-08-24 02:47:20,602 - INFO - PolishProcessor - 长文本检测，使用中等分段 (400 字符)
2025-08-24 02:47:20,603 - INFO - PolishProcessor - 处理第 1 个分段 (2874 字符, 1/1 句子)
2025-08-24 02:47:21,433 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 02:48:03,726 - INFO - PolishProcessor - 润色成功，文本长度: 2874 -> 1415
2025-08-24 02:48:03,727 - INFO - PolishProcessor - 第 1 个分段润色成功
2025-08-24 02:48:03,728 - INFO - PolishProcessor - 长文本分段处理完成，共 1 个分段
2025-08-24 02:48:03,729 - INFO - PolishProcessor - 润色完成: full_039_to_054.txt -> polished_full_039_to_054.txt (耗时: 43.13秒)
2025-08-24 02:50:14,834 - INFO - MainThread - 收到停止信号，正在关闭系统...
2025-08-24 02:50:14,834 - INFO - MainThread - 正在停止润色处理器...
2025-08-24 22:57:48,807 - INFO - MainThread - GPU内存较小(4.0GB)，调整并发数为: 2
2025-08-24 22:57:49,714 - INFO - MainThread - 润色服务初始化成功: deepseek
2025-08-24 22:57:49,715 - INFO - MainThread - 润色处理器初始化完成
2025-08-24 22:57:49,716 - INFO - MainThread - 启动语音转写系统...
2025-08-24 22:57:49,718 - INFO - MainThread - SystemManager started
2025-08-24 22:57:49,720 - INFO - MainThread - 启动独立的润色处理器...
2025-08-24 22:57:49,720 - INFO - WorkerThread-0 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 22:57:49,720 - INFO - WorkerThread-1 - 创建新的模型实例: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 22:57:49,721 - INFO - WorkerThread-0 - download models from model hub: ms
2025-08-24 22:57:49,721 - INFO - PolishProcessor - 润色处理器启动，监控目录: archive
2025-08-24 22:57:49,721 - INFO - WorkerThread-1 - download models from model hub: ms
2025-08-24 22:57:49,721 - INFO - MainThread - 润色处理器已启动
2025-08-24 22:57:56,175 - WARNING - WorkerThread-0 - trust_remote_code: False
2025-08-24 22:57:58,100 - INFO - WorkerThread-0 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 22:57:58,105 - INFO - WorkerThread-0 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 22:58:00,249 - INFO - WorkerThread-0 - scope_map: ['module.', 'None']
2025-08-24 22:58:00,250 - INFO - WorkerThread-0 - excludes: None
2025-08-24 22:58:03,005 - WARNING - WorkerThread-1 - trust_remote_code: False
2025-08-24 22:58:05,138 - INFO - WorkerThread-1 - Loading pretrained params from C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 22:58:05,148 - INFO - WorkerThread-1 - ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt
2025-08-24 22:58:08,369 - INFO - WorkerThread-1 - scope_map: ['module.', 'None']
2025-08-24 22:58:08,370 - INFO - WorkerThread-1 - excludes: None
2025-08-24 22:58:08,508 - INFO - WorkerThread-0 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 22:58:10,689 - INFO - WorkerThread-0 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 22:58:10,714 - INFO - WorkerThread-0 - 开始转写文件: 000.wav (大小: 2.00 MB)
2025-08-24 22:58:11,732 - INFO - WorkerThread-1 - Loading ckpt: C:\Users\21079\.cache\modelscope\hub\models\damo\speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch\model.pt, status: <All keys matched successfully>
2025-08-24 22:58:15,132 - INFO - WorkerThread-1 - 模型实例创建成功: damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch_cuda
2025-08-24 22:58:15,133 - INFO - WorkerThread-1 - 开始转写文件: 001.wav (大小: 2.00 MB)
2025-08-24 22:58:20,081 - INFO - WorkerThread-1 - 转写完成: 001.wav, 文本长度: 149
2025-08-24 22:58:20,081 - INFO - WorkerThread-0 - 转写完成: 000.wav, 文本长度: 76
2025-08-24 22:58:20,082 - INFO - WorkerThread-1 - transcribed seq=1 len=149
2025-08-24 22:58:20,082 - INFO - WorkerThread-0 - transcribed seq=0 len=76
2025-08-24 22:58:28,088 - INFO - MergeThread - 合并完成: archive\full_000_to_001.txt
2025-08-24 22:58:28,563 - INFO - PolishProcessor - 发现 1 个待处理文件
2025-08-24 22:58:28,563 - INFO - PolishProcessor - 开始处理文件: full_000_to_001.txt
2025-08-24 22:58:32,335 - INFO - PolishProcessor - HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-08-24 22:58:40,747 - INFO - PolishProcessor - 润色成功，文本长度: 226 -> 171
2025-08-24 22:58:40,749 - INFO - PolishProcessor - 润色完成: full_000_to_001.txt -> polished_full_000_to_001.txt (耗时: 12.17秒)
